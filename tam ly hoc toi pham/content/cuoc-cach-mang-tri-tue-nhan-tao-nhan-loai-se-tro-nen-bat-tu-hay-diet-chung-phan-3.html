<p style="text-align: justify;">Xin chào mừng tới với Phần 3 của loạt bài “Chờ đã làm sao lại như này tôi đang đọc cái quái gì vậy tại sao chẳng ai nói gì về vụ này cả.”</p> 
<p style="text-align: justify;"><span style="color: #000000;">Phần 1 bắt đầu với vẻ khá là vô hại, với việc đàm luận về Trí tuệ nhân tạo hẹp (ANI – AI được chuyên môn hóa ở một lĩnh vực hẹp như là thiết lập tuyến đường lái xe hay chơi cờ vua), và sự phổ biến của chúng trong thế giới của chúng ta hiện nay. Sau đó chúng ta đào sâu vào việc tại sao đi từ ANI tới Trí tuệ nhân tạo rộng – AGI (AI thông minh ở cấp độ con người một cách phổ quát) lại khó khăn tới vậy, và chúng ta đàm luận về tốc độ tăng trưởng hàm mũ của công nghệ mà chúng ta đã quan sát được từ quá khứ và từ đó rút ra được rằng AGI có lẽ không còn xa vời như chúng ta thường nghĩ. Phần 1 kết thúc bằng việc tôi tung chưởng rằng sự thật là một khi những cỗ máy này đạt tới mức độ thông minh như con người, tình hình có lẽ sẽ ngay lập tức thành như sau:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Train1.png"><img class="img-responsive" src="https://i2.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Train1.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><img class="img-responsive" src="https://i2.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Train2.png" alt="Train2"></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Train3.png"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Train3.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Train4-600x490.png"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Train4-600x490.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vụ này làm chúng ta ngó chòng chọc vào màn hình, đối diện với &nbsp;sự dữ dội của khả năng xuất hiện Siêu trí tuệ nhân tạo – ASI (AI thông minh vượt trội so với bất kỳ con người nào trên bất kỳ lĩnh vực nào) ngay trong cuộc đời này của chúng ta, và cố gắng tưởng tượng xem chúng ta nên cảm thấy ra sao khi nghĩ về điều này. (1)</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Trước khi chúng ta bắt đầu đi sâu hơn, hãy thử nhắc lại một chút về việc đối với một cỗ máy thì sở hữu siêu trí tuệ có nghĩa là như thế nào.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Một sự phân biệt mấu chốt nằm ở sự khác biệt giữa <em>siêu trí tuệ tốc độ</em> và <em>siêu trí tuệ chất lượng</em>. Thường thì, ý nghĩ đầu tiên của một người khi nghĩ tới một cỗ máy siêu thông minh là việc nó thông minh như con người nhưng có thể suy nghĩ với tốc độ<em> nhanh</em> hơn rất nhiều – họ có thể vẽ lên hình ảnh một cỗ máy suy nghĩ như con người nhưng nhanh hơn hàng triệu lần, tức là nó có thể xử lý một vấn đề trong vòng năm phút trong khi với con người sẽ phải mất cả thập kỷ.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nghe thì cũng ấn tượng đấy, và ASI hẳn là <em>sẽ</em> nghĩ nhanh hơn bất kỳ con người nào – nhưng điều làm nên sự khác biệt chính là lợi thế của nó trong <em>chất lượng</em> của trí tuệ, một điều hoàn toàn khác hẳn. Điều làm con người có khả năng tư duy vượt trội so với loài linh trưởng không phải là sự khác biệt về tốc độ tư duy – mà là việc não người có những mô đun nhận thức phức tạp, cho phép những thứ như là hiểu được ngôn ngữ biểu hình phức tạp hay là lập kế hoạch dài hạn hay là lập luận trừu tượng, mà bộ não linh trưởng không thể xử lý được. Tăng tốc độ xử lý của não linh trưởng lên gấp hàng ngàn lần cũng không giúp nó đạt được tới đẳng cấp của chúng ta – ngay cả khi mất tới một thập kỷ, nó cũng không thể tìm ra cách để sử dụng những công cụ có sẵn để sắp đặt một mô hình tinh vi, trong khi con người dễ dàng làm được điều này chỉ với vài giờ đồng hồ. Có hẳn một số lượng lớn các chức năng nhận thức của con người mà một loài linh trưởng khác chỉ đơn giản là không thể nắm được, dù nó có dành ra bao nhiêu thời gian đi nữa.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng không chỉ là con linh trưởng không thể làm được những điều mà chúng ta có thể, mà não nó còn không có khả năng nhận thức là những khác biệt đó thậm chí <em>có tồn tại</em> – một con linh trưởng có thể dần quen với khái niệm một con người là như thế nào, hay một tòa nhà chọc trời là ra sao, nhưng nó sẽ không bao giờ có thể hiểu được rằng tòa nhà chọc trời được <em>xây dựng</em> bởi con người. Trong thế giới của nó, tất cả những gì to lớn như vậy cũng chỉ là một phần của tự nhiên, chấm hết, và không chỉ là nó không có khả năng xây nhà, nó còn chẳng thể <em>nhận ra rằng có ai đó có thể xây nên một tòa nhà chọc trời</em>. Đó là hệ quả của một khác biệt nho nhỏ trong chất lượng của trí tuệ.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Và trong thang bậc phạm vi trí tuệ mà chúng ta đang đề cập tới hôm nay, hoặc thậm chí là phạm vi trí tuệ còn hẹp hơn nữa của các loài sinh vật, cái khoảng cách giữa chất lượng trí tuệ của loài người và loài linh trưởng là <em>siêu nhỏ</em>. Trong một bài viết trước đây, tôi mô tả thang bậc năng lực nhận thức của sinh vật bằng một chiếc cầu thang như sau:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/staircase1-586x600.png"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/staircase1-586x600.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Để thẩm thấu được mức độ khủng khiếp của một cỗ máy siêu thông minh, hãy tưởng tượng tới bậc thang màu xanh lá cây sẫm ở phía trên loài người hai bậc. Cỗ máy này chỉ thông minh hơn <em>một chút</em>, nhưng mức độ chất lượng trí tuệ mà nó vượt trên chúng ta cũng đã lớn như là chúng ta đối với loài linh trưởng vậy. Và giống như việc con linh trưởng không thể nào hiểu được rằng nhà cao tầng có thể được xây lên, chúng ta cũng sẽ chẳng bao giờ có khả năng tưởng tượng ra những điều mà cỗ máy nằm trên chúng ta hai bậc có thể làm được, kể cả khi cỗ máy đó có cố giải thích cho chúng ta – chưa kể đến việc tự mình cố hiểu chúng. Và đó chỉ là ở mức hai bậc trên chúng ta thôi. Một cỗ máy nằm trên bậc thứ hai kể từ trên đỉnh thang đối với chúng ta sẽ tương tự như chúng ta đối với loài kiến – nó có thể dành hàng năm trời nỗ lực dạy cho chúng ta những điều cơ bản nhất mà nó biết mà vẫn thành công cốc.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng thứ siêu trí tuệ mà chúng ta đề cập tới ở đây lại còn là một thứ nằm quá bất kỳ thứ gì trên bậc thang đó. Nếu như một vụ bùng nổ trí tuệ xảy ra – khi mà mỗi lần một cỗ máy trở nên thông minh hơn thì nó cũng càng nhanh chóng tự tăng cường trí tuệ của bản thân lên, cho tới khi nó <em>tăng tốc theo chiều thẳng đứng</em> – một cỗ máy có thể mất hàng năm để đi từ bậc linh trưởng lên bậc ngay trên đó, nhưng có lẽ chỉ mất vài giờ để nhảy thêm một bước nữa khi nó đã đạt tới bậc xanh lá cây sẫm trên chúng ta hai bậc, và đến lúc nó trên chúng ta mười bậc, thì có lẽ nó đã có thể nhảy bốn bậc một lần trong mỗi giây. Đó là lý do vì sao chúng ta cần phải nhận thức rằng khả năng rất cao là rất sớm thôi, ngay sau khi cái tin gây sốt về cỗ máy đầu tiên đạt được mức AGI được tung ra, chúng ta có thể sẽ phải đối mặt với thực tế là chúng ta sẽ phải cùng tồn tại với một thứ nằm ở đây trên thang trí tuệ (hay thậm chí là cao hơn gấp vài triệu lần nữa):</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/staircase2.png"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/staircase2.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Và vì chúng ta mới vừa nhận định rằng gắng hiểu một cỗ máy trên chúng ta hai bậc là hoàn toàn vô vọng, vậy thì hãy khẳng định chắc chắn một lần cho tất cả, rằng <strong>không có cách nào để biết được ASI sẽ làm gì và hệ quả của nó đối với chúng ta là gì</strong>. Tin vào điều ngược lại có nghĩa là chẳng hiểu gì về siêu trí tuệ cả.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Tiến hóa đã cải thiện bộ não sinh học một cách chậm rãi và từ từ qua hàng trăm triệu năm, và về mặt đó, nếu như loài người tạo ra một ASI, chúng ta đã vượt qua tiến hóa một cách ngoạn mục. Hoặc có thể đó là <em>một phần</em> của tiến hóa – có thể cách mà tiến hóa hoạt động chính là trí tuệ bước từng bước một cho tới khi nó đạt tới mức độ có thể tạo ra siêu trí tuệ, và mức độ đó như một kíp nổ – một ngưỡng châm ngòi – gây nên một vụ bùng nổ thay đổi hoàn toàn thế giới và quyết định một tương lai mới cho tất cả các sinh vật:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Tripwire-600x494.png"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Tripwire-600x494.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Và vì những lý do mà chúng ta sẽ đề cập tới sau đây, một phần lớn trong cộng đồng khoa học tin rằng vấn đề không nằm ở chỗ liệu chúng ta có đạt tới được ngưỡng châm ngòi&nbsp;đó không, mà là khi nào chúng ta sẽ đến đích. Một thông tin khủng đấy chứ.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy thì chúng ta còn lại gì?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Thật ra thì chẳng ai trên đời này, đặc biệt là tôi, có thể nói cho bạn hay điều gì sẽ xảy ra khi chúng ta đi tới cái mốc đó. Nhưng triết gia và nhà trí tuệ nhân tạo học hàng đầu tại Oxford, Nick Bostrom, tin rằng chúng ta có thể gộp lại tất cả những hệ quả tiềm năng thành hai nhóm lớn.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Đầu tiên là, nhìn vào lịch sử thì, chúng ta có thể thấy sự sống làm việc như sau: một loài nảy ra, tồn tại một thời gian, và rồi sau một thời gian, không thể tránh khỏi được, chúng trượt khỏi chùm thăng&nbsp;bằng tồn tại và rơi vào tuyệt chủng –</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/beam1-600x383.png"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/beam1-600x383.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">“Tất cả các loài cuối cùng đều tuyệt chủng” cũng là một quy luật chắc chắn trong lịch sử giống như là “Tất cả mọi người cuối cùng đều chết”. Cho tới nay thì 99,9% số lượng loài đã rơi khỏi chùm cân bằng, và có vẻ rất rõ ràng là nếu như một loài nào đó bám trụ lại trên chùm này đủ lâu thì cũng chỉ còn vấn đề thời gian cho tới khi một loài nào đó, hay một cơn bão của tự nhiên, hay một thiên thể bất ngờ nào đó đá văng nó xuống. Bostrom gọi tuyệt chủng là <em>điểm hút </em>(attractor state) – nơi mà tất cả mọi loài đều ngả về đó và chẳng có loài nào từ đó mà trở về cả.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Và trong khi phần lớn các nhà khoa học mà tôi từng tiếp xúc đều ghi nhận rằng ASI sẽ có khả năng đẩy loài người tới bờ vực tuyệt chủng, rất nhiều người cũng tin rằng nếu như được sử dụng một cách đúng đắn, những khả năng của ASI có thể được dùng để đưa các cá nhân, và theo đó, cả tập thể loài người với tư cách một loài, tới một điểm hút <em>thứ hai</em> – sự bất tử loài. Bostrom tin rằng sự bất tử của loài cũng là một điểm hút y hệt như là tuyệt chủng – chúng ta sẽ đánh bại được cái chết. Vậy nên dù cho tất cả các loài <em>từ trước tới giờ</em> đều đã rơi khỏi chùm thăng bằng và tuyệt chủng, Bostom tin rằng chùm này có hai hướng và chỉ đơn giản là chưa từng có loài nào trên Trái đất đủ thông minh để tìm ra cách rơi về phía bên kia.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/beam2-1024x836.jpg"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/beam2-1024x836.jpg" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nếu như Bostrom và những người khác đúng, và từ những điều tôi đã được đọc, có vẻ như họ thật sự như vậy, chúng ta sẽ phải tiếp nhận hai sự thật khá là gây sốc:</span></p> 
<ul style="text-align: justify;"> 
 <li><span style="color: #000000;"><strong>Phát minh ra ASI, lần đầu tiên trong lịch sử, mở ra cơ hội để một loài có thể rơi về phía bất tử trong chùm thăng bằng.</strong></span></li> 
 <li><span style="color: #000000;"><strong>Phát minh ra ASI sẽ tạo nên một tác động kinh ngạc tới mức không thể tượng tượng được và sẽ đẩy loài người ra khỏi chùm thăng bằng, về hướng này hay hướng khác.</strong></span></li> 
</ul> 
<p style="text-align: justify;"><span style="color: #000000;">Rất có thể là khi tiến hóa đạt tới ngưỡng châm ngòi, nó sẽ chấm dứt toàn bộ liên hệ giữa loài người với chùm dây một cách triệt để và tạo nên một thế giới hoàn toàn khác, dù là có hay không còn tồn tại con người.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Có vẻ như câu hỏi duy nhất mà bất kỳ người nào cũng nên đặt ra lúc này là: <em>Khi nào chúng ta đạt tới ngưỡng và chúng ta sẽ ngả về hướng nào khi điều đó xảy ra?</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Chẳng ai biết được câu trả lời cho bất kỳ phần nào trong câu hỏi đó, nhưng kha khá những người trong số thông minh nhất đã dành hàng thập kỷ để suy nghĩ về điều đó. Chúng ta sẽ dành phần còn lại của bài viết này để tìm hiểu xem họ đã vạch ra những gì.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">—</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Hãy bắt đầu với phần đầu tiên của câu hỏi: <em>Khi nào chúng ta sẽ chạm ngưỡng châm ngòi?</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">hay là Còn bao lâu nữa thì cỗ máy đầu tiên đạt tới mức siêu trí tuệ?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Không ngạc nhiên cho lắm, các ý kiến vô cùng đa dạng dẫn tới một cuộc tranh luận sôi nổi giữa các nhà khoa học và tư tưởng. Nhiều người trong số đó, như giáo sư <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">Vernor Vinge</a></strong></span>, nhà khoa học <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://goertzel.org/TenYearsToTheSingularity.pdf">Ben Goertzel</a></strong></span>, nhà đồng sáng lập Sun Microsystems <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.wired.com/2000/04/joy-2/">Bill Joy</a></strong></span>, hay là người nổi tiếng nhất, nhà phát minh và tương lai học <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://en.wikipedia.org/wiki/Predictions_made_by_Ray_Kurzweil">Ray Kurzweil</a></strong></span>, đồng tình với chuyên gia về mô hình hóa bằng máy (machine learning) Jeremy Howard khi ông đề xuất biểu đồ sau trong một buổi <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn?language=en">TED Talk</a></strong></span>:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Howard-Graph-1024x629.png"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Howard-Graph-1024x629.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Những người này tin rằng điều này sẽ diễn ra <em>rất sớm</em> – rằng có thể áp dụng luật tăng trưởng hàm mũ ở đây và mô hình hóa bằng máy, dù hiện nay chỉ diễn ra rất từ từ, sẽ bùng nổ trước khi chúng ta nhận ra trong vòng vài thập kỷ tới.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Những người khác, như nhà đồng sáng lập Microsoft <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.technologyreview.com/s/425733/paul-allen-the-singularity-isnt-near/">Paul Allen</a></strong></span>, nhà tâm lý học <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://www.newyorker.com/tech/elements/hyping-artificial-intelligence-yet-again">Gary Marcus</a></strong></span>, nhà khoa học máy tính NYU <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.aaai.org/ojs/index.php/aimagazine/article/view/568">Ernest Davis</a></strong></span>, và doanh nhân công nghệ <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://longbets.org/1/">Mitch Kapor</a></strong></span>, tin rằng những nhà tư tưởng như Kurweil đang <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.technologyreview.com/s/425733/paul-allen-the-singularity-isnt-near/">đánh giá quá thấp</a></strong></span> tầm cỡ thực sự của thử thách và tin rằng chúng ta chưa tiến tới gần ngưỡng tới mức đó.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Đội của Kurweil sẽ <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.technologyreview.com/s/425818/kurzweil-responds-dont-underestimate-the-singularity/">phản pháo</a></strong></span> rằng điều duy nhất bị đánh giá thấp ở đây chính là sự coi thường tăng trưởng hàm mũ, và họ sẽ so sánh những người hoài nghi với những người nhìn vào những mầm mống nảy nở chậm rãi của mạng internet vào năm 1985 để tranh luận rằng nó sẽ chẳng đi tới đâu trong tương lai gần.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Những người hoài nghi có thể sẽ phản bác rằng tiến trình cần thiết để có thể tiến lên về mặt trí tuệ <em>cũng sẽ</em> tăng lên theo hàm mũ về độ khó với mỗi bước tiến tiếp theo, và sẽ loại trừ tính tăng theo hàm mũ của tiến bộ công nghệ. Và cứ thế.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Một nhóm thứ ba, bao gồm <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.amazon.com/gp/product/0199678111/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0199678111&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=LBOTX2G2R72P5EUA">Nick Bostrom</a></strong></span>, tin rằng chẳng nhóm nào có cơ sở để dám chắc về mặt thời gian và ghi nhận cả hai điều rằng A) điều đó hoàn toàn có thể xảy ra trong tương lai gần và B) chẳng có gì để dám chắc về điều đó; nó cũng hoàn toàn có thể xảy ra trong một tương lai khá xa.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Những người khác, như triết gia <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.amazon.com/gp/product/0262540673/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0262540673&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=ZHBAVUQOM6SIGYHG">Hubert Dreyfus</a></strong></span>, tin rằng cả ba nhóm đều quá ngây thơ khi cho rằng có cái ngưỡng đó, tranh luận rằng khả năng cao là ASI thậm chí chẳng bao giờ có thể đạt được nữa.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy chúng ta có thể rút ra được gì khi xem xét tất cả những luồng quan điểm này?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vào năm 2013, Vincent C. Müller và Nick Bostrom đã tiến hành một khảo sát với hàng trăm chuyên gia về AI trong một loạt hội thảo về câu hỏi sau: “Trong giới hạn câu hỏi này, giả định rằng những hoạt động khoa học của loài người tiếp diễn mà không bị ngáng trở nào đáng kể. Bạn cho rằng tới năm nào sẽ có khả năng (10%/50%/90%) là xuất hiện HLMI (Human-level machine intelligence – hay là AGI)?” Nó yêu cầu người tham gia ghi xuống một năm lạc quan (năm mà họ tin rằng có khả năng 10% là chúng ta đạt tới AGI), một dự đoán thực tế (năm mà họ tin rằng có 50% khả năng xuất hiện AGI – hay có thể hiểu là sau năm đó họ cho rằng khả năng tồn tại AGI là cao hơn khả năng không tồn tại), và một dự đoán an toàn (năm gần nhất mà họ có thể đoán với mức chắc chắn 90% rằng chúng ta có thể có AGI). Tổng hợp dữ liệu lại cho ta kết quả sau: (2)</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Năm lạc quan trung bình(10% khả năng): <strong>2022</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Năm thực tế trung bình (50% khả năng): <strong>2040</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Năm bi quan trung bình (90% khả năng): <strong>2075</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy là ở mức trung bình người tham gia nghĩ rằng chúng ta có khả năng tương đối sẽ đạt được AGI trong vòng 25 năm tới. Câu trả lời ở mức 90% trung bình vào năm 2075 có nghĩa là nếu bây giờ bạn là một thiếu niên, thì người tham gia ở mức trung bình, cùng với hơn một nửa nhóm chuyên gia về AI, khá chắc chắn rằng AGI sẽ xuất hiện trong cuộc đời bạn.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Một nghiên cứu khác được tiến hành gần đây bởi tác giả James Barrat tại Hội thảo AGI thường niên của Ben Goertzel, đã bỏ số phần trăm đi mà chỉ hỏi rằng khi nào người tham gia cho rằng chúng ta sẽ đạt tới AGI – cho tới năm 2030, năm 2050, sau năm 2100, hay là không bao giờ. Kết quả: (3)</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Năm 2030: <strong>42% tổng số người tham gia</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Năm 2050: <strong>25%</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Năm 2100: <strong>20%</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Sau năm 2100: <strong>10%</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Không bao giờ: <strong>2%</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Khá là tương đồng với kết quả của Müller và Bostrom. Trong khảo sát của Barrat, hơn hai phần ba số người được hỏi tin rằng AGI sẽ xuất hiện trước năm 2050 và gần một nửa dự đoán sự xuất hiện của AGI trong vòng 15 năm tới. Cũng đáng chú ý như vậy là chỉ có 2% số người được hỏi cho rằng AGI sẽ không xuất hiện trong tương lai.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng AGI không phải là cái ngưỡng châm ngòi đã được nhắc tới, mà&nbsp;là ASI. Vậy những chuyên gia cho rằng tới bao giờ chúng ta sẽ đạt được ASI?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Müller và Bostrom đồng thời hỏi các chuyên gia rằng liệu họ có thấy khả năng cao là chúng ta sẽ đạt tới ASI A) trong vòng 2 năm sau khi đạt tới AGI (hay có thể hiểu là một cuộc bùng nổ trí tuệ gần như ngay lập tức), và B) trong vòng 30 năm. Kết quả là: (4)</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Câu trả lời trung bình đặt cuộc chuyển hóa từ AGI tới ASI trong vòng 2 năm ở mức <strong>10% </strong>khả năng, nhưng một cuộc chuyển hóa dài hơn trong vòng 30 năm hay ít hơn ở mức <strong>75% </strong>khả năng.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Từ số liệu này chúng ta không biết được độ dài của quá trình chuyển hóa mà người tham gia trung bình sẽ đoán là bao nhiêu ở mức 50%, nhưng để hình dung một cách tương đối, dựa trên hai câu trả lời trên, chúng ta hãy coi rằng họ sẽ nói con số này là 20 năm. Vậy thì ý kiến trung bình – con số nằm ngay chính trung tâm của giới chuyên gia AI – tin rằng dự đoán thực tế nhất về thời điểm chúng ta đạt ngưỡng ASI là [dự đoán năm 2040 về AGI + suy đoán tương đối rằng sẽ mất 20 năm để chuyển từ AGI sang ASI] = <strong>2060.</strong></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Timeline-1024x534.png"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Timeline-1024x534.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Đương nhiên, tất cả những số liệu trên đều chỉ đơn thuần là suy đoán, và chúng cũng chỉ đại diện cho mức trung bình của giới chuyên gia AI, nhưng nó có thể cho chúng ta thấy rằng một phần lớn những người hiểu biết nhất về lĩnh vực này sẽ đồng ý rằng 2060 là một suy đoán rất hợp lý cho sự xuất hiện của một ASI có thể&nbsp;thay đổi thế giới. Chỉ trong vòng 45 năm nữa thôi.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Rồi, giờ thì tới phần thứ hai của câu hỏi trên: <em>Khi chúng ta đã đạt ngưỡng châm ngòi rồi, thì chúng ta sẽ ngả về phần nào của chùm thăng bằng?</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Siêu trí tuệ sẽ mang lại quyền lực khủng khiếp – và câu hỏi quan trọng nhất cho chúng ta là:</span></p> 
<h2 style="text-align: justify;"><span style="color: #000000;"><strong>Ai hay cái gì sẽ điều khiển quyền năng ấy, và động lực của họ là gì?</strong></span></h2> 
<p style="text-align: justify;"><span style="color: #000000;">Câu trả lời sẽ quyết định liệu ASI sẽ là một công nghệ tuyệt vời không tưởng, một công nghệ tệ hại không thể hiểu nổi, hay là ở giữa khoảng đó.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Đương nhiên, giới chuyên gia lại một lần nữa bất đồng quan điểm và đang tham gia một cuộc tranh luận rất sôi nổi về câu trả lời cho câu hỏi đó. Bản khảo sát của Müller và Bostrom cũng yêu cầu người tham gia gán một con số khả năng cho những tác động có thể có của AGI đối với nhân loại và câu trả lời trung bình là có <strong>52% khả năng rằng kết quả sẽ hoặc là tốt hoặc là cực kỳ tốt và 31% khả năng rằng kết quả sẽ hoặc là xấu hoặc là cực kỳ xấu.</strong> Đối với một kết quả trung dung thì tỷ lệ trung bình chỉ là 17%. Nói như vậy nghĩa là những người biết nhiều nhất về điều này khá chắc rằng nó sẽ là một chấn động lớn. Cũng cần chú ý rằng những con số này là dành cho phát minh ra AGI – nếu như câu hỏi là về ASI, tôi tin rằng tỷ lệ trung bình cho kết quả trung dung sẽ còn thấp hơn nữa.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Trước khi chúng ta đào sâu hơn vào vấn đề hệ quả tốt hay xấu, hãy thử kết hợp hai phần “bao giờ nó sẽ xảy ra?” và phần “nó sẽ tốt hay xấu?” thành một biểu đồ tổng hợp các góc nhìn của những chuyên gia phù hợp nhất:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Square11.jpg"><img class="img-responsive" src="https://i2.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Square11.jpg" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Chúng ta sẽ bàn kỹ hơn về những quan điểm trong Khu chính trong ít phút nữa, nhưng trước tiên – bạn ngả về phía nào? Thực ra tôi biết rõ bạn nghĩ ra sao, vì tôi cũng đã từng nghĩ tương tự như bạn trước khi tìm hiểu về chủ đề này. Một số lý do mà phần lớn mọi người ít khi nghĩ về vấn đề này:</span></p> 
<ul style="text-align: justify;"> 
 <li><span style="color: #000000;">Như đã được nhắc đến ở Phần 1, phim ảnh khá là dễ gây hiểu lầm khi đưa ra những viễn cảnh không thực tế về AI khiến chúng ta cảm thấy như AI không phải là vấn đề gì nghiêm trọng lắm. James Barrat so sánh tình huống này với phản ứng của chúng ta nếu như Trung tâm Kiểm soát dịch bệnh đưa ra một thông cáo nghiêm túc về nguy cơ xuất hiện ma cà rồng trong tương lai. (5)</span></li> 
 <li><span style="color: #000000;">Do một thứ gọi là <em>thiên kiến nhận thức </em>(cognitive biases), chúng ta thường khó tin một điều gì đó là thật cho tới khi thấy bằng chứng. Tôi chắc rằng những nhà khoa học máy tính vào năm 1988 thường xuyên trao đổi về tầm ảnh hưởng của mạng internet trong tương lai, nhưng đại chúng có lẽ chẳng <em>thật sự</em> nghĩ là nó sẽ thay đổi cuộc sống của mình cho tới khi nó thật sự thay đổi cuộc sống của chúng ta. Một phần lý do là vì máy tính không thể làm được những thứ như vậy vào năm 1988, nên người ta nhìn vào máy tính và nghĩ, “Thật sao? <em>Cái thứ này </em>sẽ làm thay đổi cuộc sống á?” Trí tưởng tượng của họ bị hạn chế bởi những kinh nghiệm cá nhân về một chiếc máy tính, làm cho việc tưởng tượng máy tính có thể <em>trở nên </em>như thế nào biến thành cực kỳ khó khăn. Điều tương tự đang diễn ra với AI. Chúng ta nghe rằng có thể nó sẽ là một thứ rất lớn lao, nhưng vì nó chưa xảy ra, và vì trải nghiệm của chúng ta với những AI khá thiếu khả năng trong thế giới hiện nay, chúng ta rất khó <em>thật sự</em> tin rằng chúng sẽ thay đổi thế giới một cách đáng kinh ngạc. Và thiên kiến đó là thứ các chuyên gia đang phải đối mặt khi họ nỗ lực tìm đủ mọi cách để lôi kéo sự chú ý của chúng ta giữa&nbsp;hàng loạt những tiếng ồn của cuộc sống hàng ngày của mỗi người.</span></li> 
 <li><span style="color: #000000;">Kể cả khi chúng ta tin vào điều này – có bao nhiêu lần trong ngày hôm nay bạn nghĩ qua rằng rồi bạn sẽ không tồn tại trong phần lớn thời gian của&nbsp;vĩnh cửu? Không nhiều lắm, đúng không? Kể cả khi nó là một sự thật dữ dội hơn nhiều bất kỳ thứ gì bạn đang làm ngày hôm nay? Đó là do não của chúng ta thường tập trung vào những thứ nhỏ nhặt trong cuộc sống thường nhật, bất kể tình trạng dài hạn mà chúng ta đang phải đối mặt có điên rồ <em>đến thế nào</em>. Đó đơn giản chỉ là cách mà não chúng ta hoạt động mà thôi.</span></li> 
</ul> 
<p style="text-align: justify;"><span style="color: #000000;">Một trong những mục tiêu của hai bài viết này là nhằm kéo bạn ra khỏi Khu Tôi Muốn Nghĩ Về Những Chuyện Khác Hơn và chuyển sang một trong những Khu của chuyên gia, kể cả khi bạn chỉ đứng ở điểm giao nhau của hai đường chấm trong hình vuông phía trên, hoàn toàn không chắc chắn về bất kì cái gì.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Trong quá tình nghiên cứu, tôi đã bắt gặp hàng tá các luồng quan điểm khác nhau về chủ đề này, nhưng tôi mau chóng chú ý rằng phần lớn các quan điểm nằm trong một khu vực mà tôi gọi là Khu chính, cụ thể hơn, hơn ba phần tư số chuyên gia rơi vào trong hai Phân khu nhỏ trong Khu chính.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Square21-1024x1012.jpg"><img class="img-responsive" src="https://i2.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Square21-1024x1012.jpg" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Chúng ta sẽ đào sâu vào cả hai phân khu này. Hãy bắt đầu với điều vui vẻ hơn –</span></p> 
<h2 style="text-align: justify;"><span style="color: #000000;"><strong>Tại sao tương lai có thể là một giấc mơ tuyệt vời nhất với chúng ta</strong></span></h2> 
<p style="text-align: justify;"><span style="color: #000000;">Khi tôi tìm hiểu về thế giới AI, tôi thấy có một số lượng lớn tới đáng kinh ngạc những người đứng ở vị trí này:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Square32-1024x1012.jpg"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Square32-1024x1012.jpg" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Những người sống trong Góc Tự Tin như muốn nổ tung vì hào hứng. Họ hướng tầm nhìn về phía vui vẻ của chùm thăng bằng và tin rằng đó là nơi tất cả chúng ta đều đang đi tới. Đối với họ, tương lai là tất cả những gì họ có thể mong đợi, và nó sẽ tới vừa kịp lúc.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Điều phân biệt họ với những nhà tư tưởng khác mà chúng ta sẽ bàn tới sau không phải là khát khao về một chiều hướng hạnh phúc của tương lai – mà là sự tự tin rằng đó là nơi chúng ta sẽ tới.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Khởi nguồn của sự tự tin này thì lại còn phải xem xét. Những nhà phê bình tin rằng nó đến từ một sự hào hứng đến mù quáng làm cho họ lờ tịt đi hoặc phủ nhận những hệ quả tiêu cực có thể xảy ra. Nhưng những người tin tưởng thì cho rằng quả là ngây thơ khi vẽ ra một viễn cảnh của ngày tận thế trong khi nhìn một cách tổng quát, công nghệ đã và có lẽ sẽ tiếp tục giúp đỡ chúng ta hơn là làm hại chúng ta.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Chúng ta sẽ nói về cả hai phía, và bạn có thể tự đưa ra quan điểm của mình trong lúc đọc bài, nhưng trong phần này, hãy đặt sự nghi ngại sang một bên và thử đưa mình nhìn vào những điều hay ho có thể xảy ra ở phần này của chùm thăng bằng – và gắng tiếp nhận sự thật rằng những điều mà bạn đang đọc <em>hoàn toàn có thể xảy ra</em>. Nếu như bạn cho một người ở thời săn bắt hái lượm xem thế giới có nơi trú ẩn trong nhà thoải mái tiện nghi, công nghệ và sự dồi dào của cải vật chất, cảnh đó sẽ giống như là phép thuật viễn tưởng đối với anh ta – chúng ta cần phải thật khiêm tốn để ghi nhận rằng hoàn toàn <em>có thể</em> đây sẽ là một chuyển biến vĩ đại tương tự trong tương lai chúng ta.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nick Bostrom mô tả ba cách mà một hệ thống AI siêu trí tuệ có thể hoạt động: (6)</span></p> 
<ul style="text-align: justify;"> 
 <li><span style="color: #000000;">Như một <strong>Kẻ-biết-tuốt</strong>, trả lời gần như bất kỳ câu hỏi nào được đặt ra cho nó một cách chuẩn xác, bao gồm cả những câu hỏi phức tạp mà loài người khó có thể trả lời một cách dễ dàng: – như là <em>Làm thế nào để sản xuất một động cơ xe hơi hiệu suất cao hơn?</em> Google là một dạng kẻ-biết-tuốt thô sơ.</span></li> 
 <li><span style="color: #000000;">Như một <strong>Thần đèn<em>, </em></strong>thi hành mọi mệnh lệnh bậc cao được đưa ra cho nó – <em>Sử dụng một máy lắp ráp phân tử để xây dựng một động cơ xe hơi mới với hiệu suất cao hơn</em> – và rồi chờ đợi mệnh lệnh tiếp theo.</span></li> 
 <li><span style="color: #000000;">Như một <strong>Đấng tối cao</strong>, được đưa cho những mục tiêu mở chung chung và được cho phép vận hành tự do trong thế giới, tự đưa ra những quyết định cho chính nó để tiến hành một cách tốt nhất – <em>Tạo ra một cách nhanh hơn, rẻ hơn và an toàn hơn xe hơi để con người có thể di chuyển một cách riêng tư</em>.</span></li> 
</ul> 
<p style="text-align: justify;"><span style="color: #000000;">Những câu hỏi này có vẻ phức tạp đối với chúng ta, nhưng đối với siêu trí tuệ thì cũng chỉ giống như có ai đó hỏi chúng ta cách xử lý tình huống “Bút chì của tôi rơi khỏi cái bàn”, mà bạn sẽ xử lý bằng cách nhặt nó lên và đặt nó lại trên bàn.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://yudkowsky.net/">Eliezer Yudkowsky</a></strong></span>, một người cư trú tại Đường E Ngại trên biểu đồ phía trên của chúng ta, đã tóm lại một cách tuyệt vời:</span></p> 
<table width="678"> 
 <tbody> 
  <tr> 
   <td width="638"><span style="color: #000000;"><em>Không có v</em><em>ấ</em><em>n đ</em><em>ề</em><em> nào là khó khăn, ch</em><em>ỉ</em><em> có nh</em><em>ữ</em><em>ng v</em><em>ấ</em><em>n đ</em><em>ề</em><em> khó đ</em><em>ố</em><em>i v</em><em>ớ</em><em>i m</em><em>ộ</em><em>t m</em><em>ứ</em><em>c đ</em><em>ộ</em><em> nh</em><em>ấ</em><em>t đ</em><em>ị</em><em>nh c</em><em>ủ</em><em>a trí tu</em><em>ệ</em><em>. Ti</em><em>ế</em><em>n thêm m</em><em>ộ</em><em>t b</em><em>ướ</em><em>c nh</em><em>ỏ</em><em> [trên thang trí tu</em><em>ệ</em><em>], và m</em><em>ộ</em><em>t vài v</em><em>ấ</em><em>n đ</em><em>ề</em><em> s</em><em>ẽ</em><em> b</em><em>ấ</em><em>t ch</em><em>ợ</em><em>t chuy</em><em>ể</em><em>n t</em><em>ừ</em><em> “b</em><em>ấ</em><em>t kh</em><em>ả</em><em> thi” sang “hi</em><em>ể</em><em>n nhiên.” Ti</em><em>ế</em><em>n thêm m</em><em>ộ</em><em>t b</em><em>ướ</em><em>c đ</em><em>ủ</em><em> l</em><em>ớ</em><em>n và t</em><em>ấ</em><em>t c</em><em>ả</em><em> b</em><em>ỗ</em><em>ng đ</em><em>ề</em><em>u tr</em><em>ở</em><em> thành hi</em><em>ể</em><em>n nhiên.</em><em>&nbsp;</em>(7)</span></td> 
  </tr> 
 </tbody> 
</table> 
<p style="text-align: justify;"><span style="color: #000000;">Có rất nhiều nhà khoa học, nhà phát minh và doanh nhân đầy nhiệt huyết cư ngụ ở Góc Tự Tin – nhưng để có một chuyến du hành tới nơi tươi sáng nhất trong chân trời AI, chỉ có một người mà chúng ta muốn mời làm hướng dẫn viên.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Ray Kurzweil là một nhân vật gây phân cực mạnh mẽ. Trong quá trình đọc, tôi đã thấy tất cả các quan điểm từ tôn thờ ông và tư tưởng của ông như Chúa cho tới sự khinh miệt rõ ràng. Những quan điểm khác thì nằm đâu đó trong khoảng giữa – tác giả Douglas Hofstadter, khi thảo luận về những ý tưởng trong sách của Kurweil, đã diễn đạt rằng “như thể là bạn vừa ăn một đống thức ăn tuyệt hảo trộn lẫn với phân chó và bạn chẳng thế phân biết được cái gì tốt hay tệ nữa.”</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Dù bạn có thích những ý tưởng của ông hay không, tất cả đều đồng tình rằng Kurzweil rất ấn tượng. Ông bắt đầu sáng chế từ thời thiếu niên và trong những thập niên sau đó, ông đã mang lại một số sáng chế mang tính đột phá, bao gồm máy quét phẳng (flatbed scanner) đầu tiên, máy quét đầu tiên có thể chuyển văn tự thành ngôn ngữ nói (giúp người mù có thể đọc được chữ viết thông thường), đàn synthesizer đầu tiên (chiếc đàn piano điện thật sự đầu tiên), và máy nhận diện ngôn ngữ nói với vốn từ rộng được quảng bá thương mại rộng rãi đầu tiên. Ông cũng là tác giả của năm cuốn sách bán chạy nhất nước. Ông nổi tiếng bởi những dự đoán của mình và có một <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://bigthink.com/endless-innovation/why-ray-kurzweils-predictions-are-right-86-of-the-time">thành tích dự đoán trúng</a></strong></span> tương đối cao – bao gồm dự đoán từ những năm cuối thập kỷ 80, thời kỳ mà mạng internet vẫn là một thứ bí hiểm, rằng nó rồi sẽ trở thành một hiện tượng toàn cầu. Kurzweil đã được gọi là “thiên tài không ngừng nghỉ” bởi tờ Thời Báo Phố Wall, “cỗ máy tư duy tối thượng” bởi Forbes, “ người kế thừa xứng đáng của Edison” bởi tạp chí Inc., và “người giỏi nhất tôi biết về dự đoán tương lai của trí tuệ nhân tạo” bới Bill Gates. (9) Vào năm 2012, nhà đồng sáng lập Google Larry Page đã tiếp xúc với Kurzweil và đề nghị ông làm việc với&nbsp;tư cách giám đốc kỹ thuật của Google. Vào năm 2011, ông đã đống sáng lập ra <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://singularityu.org/">đại học Singularity</a></strong></span>, được tổ chức bởi NASA và được tài trợ một phần bới Google. Một cuộc đời không tệ.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Đoạn tiểu sử này khá là quan trọng. Khi Kurzweil trình bày dự đoán của ông về tương lai, nghe ông cứ như thể đang phê cần vậy, và điều điên rồ ở đây là sự thật không hề như thế – ông là một người hết sức thông minh, hiểu biết và hoàn toàn sáng suốt. Bạn có thể nghĩ rằng ông đã sai khi dự đoán về tương lai, nhưng ông không phải là một kẻ đần độn. Biết rằng ông là một nhân vật đáng tin cậy khiến tôi thấy<em> vui sướng</em>, bởi khi tôi đã biết được những dự đoán về tương lai của ông, tôi <em>cực kỳ</em> mong là ông đúng. Và bạn cũng vậy. Khi bạn nghe về những dự đoán của Kurzweil, được đồng tình bởi những nhà tư tưởng thuộc Góc Tự Tin như <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://www.diamandis.com/">Peter Diamandis</a></strong></span> và <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://en.wikipedia.org/wiki/Ben_Goertzel">Ben Goertzel</a></strong></span>, bạn sẽ thấy không khó hiểu tại sao ông lại thu thập được một lượng lớn những người ủng hộ nhiệt tình đến vậy – họ được gọi là những “singularitarian”. Ông nghĩ rằng tương lai sẽ như thế này:</span></p> 
<h2 style="text-align: justify;"><span style="color: #000000;"><strong>Dòng thời gian</strong></span></h2> 
<p style="text-align: justify;"><span style="color: #000000;">Kurzweil tin rằng máy tính sẽ đạt được mốc AGI vào năm 2029 và rằng tới năm 2045, chúng ta không chỉ có được ASI, mà còn có một thế giới mới không tưởng tượng nổi – thời điểm mà ông gọi là điểm dị biệt (singularity). Dòng thời gian mà ông đưa ra từng bị coi là quá sức lạc quan, và cho tới giờ nhiều người vẫn coi nó như vậy, nhưng trong 15 năm trở lại đây, những tiến trình đạt được về các hệ thống ANI đã đưa giới chuyên gia AI đã trở nên đông đảo hơn tới gần hơn với dòng thời gian của Kurzweil. Những dự đoán của ông vẫn là tương đối tham vọng đối với một người tham gia trung bình trong khảo sát của Müller và Bostrom (AGI vào năm 2040, ASI vào năm 2060), nhưng cũng không hẳn là cách xa lắm.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Mô tả của Kurzweil về điểm dị biệt năm 2045 là nó sẽ xảy ra do ba cuộc cách mạng đồng thời trong công nghệ sinh học, công nghệ nano, và mạnh mẽ hơn hết, là AI.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Trước khi chúng ta đi tiếp – công nghệ nano xuất hiện trong phần lớn mọi thứ bạn đọc về tương lai của AI, vậy nên hãy lướt qua ô màu xanh này trong một phút để chúng ta có thể bàn luận về nó –</span></p> 
<h2 style="text-align: justify;">&nbsp;Đọc 6 phần ở đây:</h2> 
<h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-con-duong-toi-sieu-tri-tue-phan-1">Cuộc cách mạng trí tuệ nhân tạo: Con đường tới Siêu trí tuệ (Phần 1)</a></span></h4> 
<h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-con-duong-toi-sieu-tri-tue-phan-2">Cuộc cách mạng trí tuệ nhân tạo: Con đường tới Siêu trí tuệ (Phần 2)</a></span></h4> 
<h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung-phan-3">Cuộc cách mạng trí tuệ nhân tạo: Nhân loại sẽ trở nên bất tử hay diệt chủng? (Phần 3)</a></span></h4> 
<h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung-phan-4">Cuộc cách mạng trí tuệ nhân tạo: Nhân loại sẽ trở nên bất tử hay diệt chủng? (Phần 4)</a></span></h4> 
<div class="composs-main-article-head"> 
 <h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung-phan-5">Cuộc cách mạng trí tuệ nhân tạo: Nhân loại sẽ trở nên bất tử hay diệt chủng? (Phần 5)</a></span></h4> 
 <div class="composs-main-article-head"> 
  <h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung-phan-6">Cuộc cách mạng trí tuệ nhân tạo: Nhân loại sẽ trở nên bất tử hay diệt chủng? (Phần 6)</a></span></h4> 
 </div> 
</div> 
<p><strong>Dịch</strong>:&nbsp;<a href="https://liemaximun1208.wordpress.com/2017/03/16/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung/">https://liemaximun1208.wordpress.com/2017/03/16/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung/</a></p> 
<p><strong>Nguồn</strong>:&nbsp;<a href="http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html">http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html</a></p>