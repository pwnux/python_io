<table> 
 <tbody> 
  <tr> 
   <td width="638"><span style="color: #000000;"><strong>Ô xanh về Công nghệ Nano</strong></span> <p><span style="color: #0000ff;">Công nghệ Nano là từ dùng để chỉ công nghệ được sử dụng để xử lý vật chất với kích cỡ từ 1 tới 100 nano mét. Một nano mét bằng một phần tỷ mét, hay là một phần triệu mili mét, và giới hạn từ 1 tới 100 này bao gồm vi rút (khoảng 100 nm), DNA (rộng cỡ 10 nm), và những thứ nhỏ như các phân tử lớn ví dụ như hemoglobin (5 nm) và phân tử cỡ trung như glucose (1 nm). Nếu như/khi chúng ta chinh phục được công nghệ nano, bước tiếp theo sẽ là khả năng điều khiển những nguyên tử độc lập, với kích cỡ chỉ nhỏ hơn 1 bậc (khoảng 0.1 nm).</span></p> <p><span style="color: #0000ff;">Để hiểu được thử thách của loài người khi xử lý những vật chất nhỏ cỡ này, hãy thử xem xét điều tương tự ở quy mô lớn hơn. Trạm Vũ trụ Quốc tế nằm ở vị trí 268 dặm (431 km) phía trên Trái đất. Nếu như con người là những người khổng lồ lớn đến độ đầu chúng ta với tới được trạm ISS, chúng ta sẽ lớn hơn mức hiện nay là 250,000 lần. Nếu như bạn phóng đại khoảng 1 – 100 nm của công nghệ nano gấp 250,00 lần, bạn sẽ đạt mức 0.25 mm – 2.5 cm. Vậy công nghệ nano tương đương với việc một người khổng lồ cao như trạm ISS gắng tìm cách dựng những đồ vật phức tạp một cách tỉ mỉ, sử dụng vật liệu nằm trong khoảng kích cỡ từ một hạt cát cho tới một nhãn cầu. Để đạt được tới ngưỡng tiếp theo – điều khiển những nguyên tử riêng biệt – người khổng lồ sẽ phải cẩn thận sắp đặt các vật thể cỡ 1/40 mm – nhỏ tới mức những người cỡ bình thường sẽ cần tới kính hiển vi để nhìn thấy chúng.</span></p> <p><span style="color: #0000ff;">Công nghệ nano đã được thảo luận lần đầu tiên bởi Richard Feynman trong một bài nói chuyện năm 1959, khi ông giải thích rằng: “Nguyên lý của vật lý, theo những gì tôi được biết, không phủ định khả năng thao tác ở cấp phân tử. Theo lý thuyết thì một nhà vật lý có thể tổng hợp bất kỳ chất hóa học nào mà nhà hóa học viết ra… Bằng cách nào? Đặt những phân tử xuống những nơi mà nhà hóa học chỉ, và rồi bạn có thể tạo ra chất đó.” Đơn giản là như vậy thôi. Nếu như bạn có thể tìm ra cách di chuyển những phân tử hay nguyên tử riêng lẻ, bạn có thể tạo ra mọi thứ theo đúng nghĩa đen.</span></p> <p><span style="color: #0000ff;">Công nghệ nano đã trở thành một lĩnh vực nghiêm túc lần đầu tiên vào năm 1986, khi kỹ sư Eric Drexler đặt nền móng cho nó bằng cuốn tài liệu hội thảo <em>Kỹ thuật Tạo tác</em>, nhưng Drexler cho rằng những người muốn hiểu biết nhiều hơn về những tư tưởng hiện đại nhất trong công nghệ nano nên đọc cuốn sách được xuất bản năm 2013 của ông, <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.amazon.com/gp/product/1610391136/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1610391136&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=AIDAWXXXQCHLBDCU"><em>Sự dồi dào căn bản</em></a></strong></span> (Radical Abundance).</span></p> 
    <table width="662"> 
     <tbody> 
      <tr> 
       <td width="623"><span style="color: #000000;"><strong>Ô xanh hơn về Chất nhờn xám (Gray Goo)</strong></span> <p><span style="color: #0000ff;">Chúng ta hiện nay đang ở một ghi chú <em>bên trong một ghi chú</em>. Thật thú vị quá đi mất!</span></p> <p><span style="color: #0000ff;">Dù sao thì, tôi đưa bạn tới đây vì đây là một phần hết sức kém vui về kiến thức công nghệ nano mà tôi cần phải cho bạn biết. Trong một phiên bản cũ hơn của học thuyết công nghệ nano, một phương án được đề xuất cho dây chuyền nano bao gồm việc tạo ra hàng tỷ tỷ những robot nano (nanobot) cùng phối hợp để xây dựng thứ gì đó. Một cách để tạo ra những nanobot này sẽ là làm một chiếc có khả năng tự nhân đôi và rồi để quá trình đó biến một con thành hai con, rồi hai con đó biến thành bốn, bốn biến thành tám, và trong vòng khoảng 1 ngày, sẽ có khoảng vài tỷ tỷ con sẵn sàng vào vị trí. Đó là sức mạnh của tăng trưởng hàm mũ. Thông minh quá phải không?</span></p> <p><span style="color: #0000ff;">Thông minh cho tới khi chính việc đó tạo ra một thảm họa tận thế quy mô hành tinh&nbsp;do tai nạn. Vấn đề là chính sức mạnh của tăng trưởng hàm mũ đã giúp tạo ra hàng tỷ tỷ con nanobot cũng làm cho quá trình tự nhân đôi là một khả năng <em>vô cùng đáng sợ</em>. Bởi vì điều gì sẽ xảy ra nếu hệ thống bị lỗi, và thay vì ngừng khi đạt tới mức một tỷ tỷ nanobot, nó lại cứ tiếp tục nhân đôi? Những con robot nano sẽ được thiết kế để “ăn” bất kỳ thứ gì có gốc carbon nhằm cung cấp cho quá trình nhân đôi, và không vui vẻ gì lắm, tất cả các sinh thể đều có gốc carbon. Tập sinh quyển của Trái đất chứa khoảng 10^45 nguyên tử carbon. Một nanobot sẽ chứa khoảng 10^6 nguyên tử carbon, vậy thì 10^39 nanobot sẽ hấp thụ toàn bộ sinh thể trên trái đất, và điều này sẽ xảy ra sau khoảng 130 lần nhân đôi (2^130 xấp xỉ 10^39), khi một biển các nanobot (đó chính là chất nhờn xám) tràn ra khắp hành tinh. Các nhà khoa học nghĩ rằng một nanobot có thể nhân đôi trong khoảng 100 giây, tức là lỗi nhỏ này sẽ tiêu diệt toàn bộ sự sống trên Trái đất một cách không dễ chịu gì trong chỉ có 3.5 giờ đồng hồ.</span></p> <p><span style="color: #0000ff;">Một tình huống tồi tệ hơn – là nếu như một tên khủng bố bằng cách nào đó có được công nghệ nano và có đủ kiến thức để lập trình chúng, hắn ta có thể trước tiên tạo ra vài tỷ con rồi lập trình chúng để chúng lặng lẽ tràn ra khắp hành tinh mà không bị phát hiện. Rồi sau đó, chúng đồng loạt phát động tấn công, và rồi chỉ mất 90 phút để chúng hấp thu tất cả mọi thứ – và khi chúng lan tới mọi ngõ ngách như vậy thì chẳng có cách nào để đối phó được với chúng.</span></p> <p><span style="color: #0000ff;">Trong khi câu chuyện kinh dị này đã được thảo luận rộng rãi trong nhiều năm, thì tin tốt là nó có thể chỉ là thái quá – Eric Drexler, cha đẻ của thuật ngữ “chất nhờn xám,” gửi cho tôi một email sau bài viết này về suy nghĩ của ông về viễn cảnh chất nhờn xám: “Mọi người đều thích những câu chuyện đáng sợ, và vụ này cũng giống như vụ zombie vậy. Bản thân ý tưởng đó đã muốn ăn mòn não rồi.”</span></p> </td> 
      </tr> 
     </tbody> 
    </table> <p>&nbsp;</p> <p><span style="color: #000000;">Một khi chúng ta đã chinh phục được công nghệ nano, chúng ta có thể dùng nó để làm ra những sản phẩm công nghệ, quần áo, đồ ăn, một loạt các sản phẩm liên quan tới sinh thể – như là tế bào máu nhân tạo, vi rút hay các cỗ máy phá hủy tế bào ung thư, các mô cơ, vân vân – bất kỳ thứ gì. Và trong một thế giới sử dụng công nghệ nano, chi phí của một vật liệu không còn phụ thuộc vào độ hiếm của nó hay mức độ khó khăn của quy trình sản xuất, mà thay vào đó là mức độ phức tạp của cấu tạo nguyên tử của nó. Trong một thế giới có công nghệ nano, một viên kim cương có thể rẻ hơn cả một cục tẩy bút chì.</span></p> <p><span style="color: #000000;">Chúng ta chưa đi được tới đó. Và cũng không rõ liệu chúng ta đang đánh giá quá thấp, hay quá cao, độ khó của hành trình đi tới đó. Nhưng chúng ta có vẻ không ở quá xa ngày đó. Kurweil dự đoán là chúng ta sẽ đạt được điều này vào năm 2020. (11) Các chính phủ biết rằng công nghệ nano có thể sẽ là một bước tiến làm rung chuyển thế giới, và họ đã đầu tư hàng tỷ đô vào việc nghiên cứu công nghệ nano (Mỹ, châu Âu và Nhật bản đã đầu tư tổng cộng là 5 tỷ đô). (12)</span></p> <p><span style="color: #000000;">Chỉ xem xét tới khả năng một máy tính siêu trí tuệ có thể tiếp cận một dây chuyền sản xuất nano mạnh mẽ đã là quá điên rồ. Nhưng công nghệ nano là thứ mà <em>chúng ta </em>đã kiến tạo ra, và đang trong quá trình đạt tới nó, và vì tất cả những gì chúng ta có thể làm được chỉ là một trò đùa với một hệ thống ASI, chúng ta cần mặc định rằng ASI sẽ còn nghĩ tới những công nghệ còn quyền năng hơn và tiến bộ đến mức vượt quá khả năng tiếp thu của bộ não người. Vì lý do này, khi xem xét viễn cảnh “Nếu cuộc cách mạng AI lại hóa ra quá lợi cho chúng ta”, gần như là không thể đánh giá quá cao tầm vóc của những gì có thể diễn ra – vậy nếu như những dự đoán về tương lai của ASI có vẻ như quá xa vời, hãy nhớ rằng chúng có thể diễn biến theo những cách&nbsp;mà chúng ta thậm chí chẳng thể tưởng tượng ra nổi. Khả năng cao nhất là, não của chúng ta thậm chí còn chẳng có năng lực để mà dự đoán những điều có thể xảy ra được nữa.</span></p> </td> 
  </tr> 
 </tbody> 
</table> 
<p style="text-align: justify;"><span style="color: #000000;">&nbsp;</span></p> 
<h3 style="text-align: justify;"><span style="color: #000000;"><strong>Những điều AI có thể làm cho chúng ta</strong></span></h3> 
<p><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/only-humans-cartoon.jpg"><img class="img-responsive" style="display: block; margin-left: auto; margin-right: auto;" src="https://i2.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/only-humans-cartoon.jpg" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Được trang bị bởi siêu trí tuệ và tất cả những công nghệ mà siêu trí tuệ sẽ biết cách tạo ra, ASI có lẽ sẽ có khả năng giải quyết mọi vấn đề của nhân loại. Sự nóng lên toàn cầu? ASI có thể trước tiên giảm phát thải CO2 bằng cách vạch ra những cách tốt hơn nhiều để tạo ra năng lượng mà không cần tới than hóa thạch. Rồi thì nó có thể tạo ra những cách vô cùng tiên tiến để bắt đầu loại bỏ CO2 dư thừa ra khỏi khí quyển. Ung thư hay những dịch bệnh khác? Không là gì đối với ASI – sức khỏe và thuốc men sẽ được cải cách đến độ không thể tưởng tượng nổi. Nạn đói? ASI có thể sử dụng những thứ như là công nghệ nano để <em>tạo ra</em> thịt từ không khí với <em>cấu tạo phân tử tương tự</em> như thịt thật – nói cách khác đó <em>chính là </em>thịt thật. Công nghệ nano có thể biến một đống rác thành một tảng thịt lớn tươi rói hay những loại thực phẩm khác (mà không hẳn phải có dạng như đồ ăn bình thường – cứ tưởng tượng một khối táo thập phương lớn) – và phân phát lượng thức ăn này đến khắp mọi nơi trên thế giới bằng công nghệ giao thông tối tân. Đương nhiên, điều này cũng sẽ rất tuyệt vời đối với các loài động vật, vì chúng sẽ không bị giết hại bởi con người nhiều lắm nữa, và ASI cũng có thể làm rất nhiều điều khác để bảo tồn những loài đang trên đà tuyệt chủng và thậm chí có thể mang những loài đã tuyệt chủng trở lại bằng cách làm việc với những DNA được bảo lưu. ASI cũng có thể giải quyết được những vấn đề vĩ mô phức tạp nhất – những cuộc tranh luận quanh việc nền kinh tế nên được vận hành ra sao và thương mại thế giới được thúc đẩy thế nào, ngay cả những vấn đề tù mù nhất về triết học hay đạo đức – cũng sẽ đều hết sức hiển nhiên đến mức đáng sợ với ASI.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng có một điều mà ASI có thể làm cho chúng ta, vĩ đại <em>cực kỳ</em>, và đọc về nó đã thay đổi tất cả hiểu biết mà tôi tin là tôi có về mọi điều:</span></p> 
<h3 style="text-align: justify;"><span style="color: #000000;"><strong><em>ASI có thể cho phép chúng ta chinh phục cái chết</em>.</strong></span></h3> 
<p style="text-align: justify;"><span style="color: #000000;">Một vài tháng trước, tôi đã <a style="color: #000000;" href="http://waitbutwhy.com/2014/05/fermi-paradox.html">nhắc tới</a> việc tôi ghen tị thế nào với những nền văn minh tân tiến tương lai, khi mà cái chết đã bị chinh phục, chưa từng thoáng nghĩ tới khả năng sau đó tôi có thể viết một bài làm cho tôi thực lòng tin tưởng rằng đó là một điều mà loài người có thể đạt được trong thời gian tôi còn sống. Nhưng đọc về AI sẽ làm cho bạn suy nghĩ lại về <em>mọi thứ</em> mà bạn nghĩ bạn chắc chắn là bạn đúng – bao gồm cả về cái chết.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Tiến hóa chẳng có lý do mật thiết nào để kéo dài thời gian sống của sinh thể hơn mức hiện tại. Nếu chúng ta sống đủ lâu để sinh sản và nuôi con cái tới một độ tuổi mà chúng có thể tự bảo vệ mình, như thế đã là đủ đối với tiến hóa – nhìn từ quan điểm của tiến hóa, một loài có thể tiếp tục duy trì với thời gian sống của sinh thể là hơn&nbsp; 30 năm, vậy nên không có lý do gì để cho những cá thể dị biệt với một đời sống được kéo dài hơn mức thông thường có được lợi thế&nbsp; trong quá trình chọn lọc tự nhiên. Kết quả là, chúng ta được W.B. Yeats mô tả như “những linh hồn bị trói buộc vào một sinh vật đang chết dần.” (13) Chẳng vui vẻ chút nào.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Và bởi vì tất cả mọi người trước giờ vẫn chết, chúng ta sống với mặc định “cái chết và sự trả nợ”, hay là cái chết là điều không thể tránh khỏi. Chúng ta nghĩ về việc già đi giống như là thời gian vậy – cả hai đều chuyển động và không gì ngăn được chúng .<em> Nhưng mặc định đó là sai lấm</em>. Richard Feynman viết rằng:</span></p> 
<table width="652"> 
 <tbody> 
  <tr> 
   <td width="638"><span style="color: #0000ff;"><em>Một trong những thứ đáng chú ý nhất trong tất cả những ngành khoa học sinh học là không có bằng chứng nào cho sự cần thiết của cái chết. Nếu bạn nói rằng chúng ta muốn tạo ra động cơ vĩnh cửu, thì chúng ta đã tìm ra được đủ các quy luật vật lý để nhận thấy rằng hoặc điều đó là bất khả, hoặc là các quy luật đó sai. Nhưng không có gì trong các khám phá của ngành sinh học cho thấy sự cần thiết của cái chết. Điều này làm cho tôi nghĩ rằng có lẽ nó là hoàn toàn có thể tránh được và chỉ là vấn đề thời gian cho tới khi những nhà sinh vật học tìm ra nguyên nhân gây ra rắc rối này và dịch bệnh toàn cầu tệ hại này hay là sự hữu hạn của cơ thể người rồi sẽ được chữa khỏi.</em></span></td> 
  </tr> 
 </tbody> 
</table> 
<p style="text-align: justify;">&nbsp;</p> 
<p style="text-align: justify;"><span style="color: #000000;">Sự thật là, sự lão hóa không hề bị <em>gắn chặt</em>&nbsp;vời thời gian. Thời gian <em>phải</em> tiếp tục tịnh tiến, nhưng <em>sự lão hóa thì không hẳn như vậy.</em> Nếu bạn thử nghĩ về điều đó thì thực ra nó rất hợp lý. Sự lão hóa chính là những vật chất cấu tạo nên cơ thể bị cũ mòn đi. Một chiếc xe ô tô qua thời gian cũng bị cũ mòn đi – nhưng nó có nhất thiết bị lão hóa không? Nếu như bạn sửa chữa hoặc thay thế những phần của ô tô khi chúng bắt đầu cũ mòn một cách hoàn hảo, chiếc xe sẽ chạy mãi. Cơ thể người cũng không khác gì – chỉ là phức tạp hơn.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Kurzweil trình bày về những robot&nbsp;nano có trí tuệ được kết nổi bởi wifi trong hệ tuần hoàn, chúng có thể thực hiện vô số các nhiệm vụ vì sức khỏe con người bao gồm việc thay thế thường xuyên những tế bào đã cũ ở bất kì phần nào của cơ thể. Nếu được hoàn thiện, quá trình này (hoặc một quá trình khác còn thông minh hơn mà ASI có thể đề xuất ra) sẽ không những chỉ giữ cho cơ thể khỏe mạnh, nó thậm chí còn <em>đảo ngược quá trình lão hóa. </em>Sự khác biệt giữa một cơ thể 60 tuổi và một cơ thể 30 tuổi chỉ là một loạt các tính chất vật lý hoàn toàn có thể thay đổi được nếu chúng ta có công nghệ thích hợp. ASI có thể xây dựng một cỗ máy “đảo ngược tuổi tác” mà một người 60 tuổi có thể bước vào, và rồi bước ra với cơ thể và làn da của người 30 tuổi. Ngay cả bộ não luôn rất phức tạp cũng có thể được làm mới bởi một thứ thông minh như là ASI, nó sẽ tìm ra cách làm việc đó mà không ảnh hưởng đến những dữ liệu của não (tính cách, ký ức, v.v.). Một người 90 tuổi mắc chứng suy giảm trí nhớ có thể đi vào cỗ máy đảo ngược tuổi tác và trở ra sắc bén như mới, sẵn sàng cho một sự nghiệp hoàn toàn mới mẻ. Điều này nghe có vẻ điên rồ – nhưng cơ thể chẳng qua chỉ là một tập hợp các nguyên tử và ASI mặc nhiên có thể đễ dàng điều khiển tất cả các dạng cấu trúc nguyên tử – nên thực ra điều đó <em>chẳng</em> <em>điên rồ</em> chút nào.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Kurzweil sau đó còn tiến thêm một bước lớn nữa. Ông tin rằng các vật liệu nhân tạo có thể được tích hợp vào trong cơ thể ngày một nhiều hơn theo thời gian. Đầu tiên, các nội tạng có thể được thay thế bởi các phiên bản bằng máy tân tiến có thể chạy suốt mà không bao giờ hỏng hóc. Sau đó ông tin rằng chúng ta có thể bắt đầu tái cấu trúc cơ thể – những thứ như thay thế các tế bào máu đỏ bằng các robot nano với chức năng tương tự nhưng hoàn thiện hơn và có thể tự cung cấp năng lượng cho hoạt động của mình dẫn tới việc <em>hoàn toàn </em>không cần có quả tim nữa. Ông thậm chí còn đề cập tới bộ não và tin rằng chúng ta sẽ <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.youtube.com/watch?v=PVXQUItNEDQ">tăng cường hoạt động của não</a></strong></span> tới mức con người sẽ có khả năng <em>suy nghĩ</em> nhanh gấp vài tỷ lần so với hiện nay và tiếp cận các thông tin ngoại lai bởi vì những phần phụ trợ nhân tạo được cấy thêm vào não sẽ có thể giao tiếp với tất cả các thông tin trong đám mây dữ liệu.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Những khả năng cho trải nghiệm mới của con người sẽ là vô hạn. Con người đã tách rời tình dục với mục đích chính của nó, cho phép người ta có thể quan hệ vì cảm giác chứ không phải chỉ cho mục đích sinh sản. Kurzweil tin rằng chúng ta sẽ có thể làm điều tương tự với thức ăn. Các nanobot sẽ có nhiệm vụ vận chuyển các chất dinh dưỡng tinh khiết nhất tới các tế bào trong cơ thể, điều hướng cho bất kỳ thứ gì có hại cho sức khỏe di chuyển qua cơ thể mà không ảnh hưởng tới bất kỳ thứ gì. Một loại bao cao su cho việc ăn uống. Nhà lý thuyết công nghệ nano Robert A. Freitas đã thực tế thiết kế những bản thay thế cho tế bào máu mà, nếu một ngày được cấy vào cơ thể, sẽ cho phép một người chạy nhanh 15 phút liền mà không cần thở – nên bạn có thể tưởng tượng rằng ASI còn làm được những gì đối với năng lực thể chất của chúng ta nữa. Thực tế ảo sẽ mang một ý nghĩa mới – những nanobot trong cơ thể có thể chặn lại các tín hiệu từ yếu tố đầu vào được tiếp nhận bởi các giác quan và thay thế chúng bằng những tín hiệu mới, đặt chúng ta vào một môi trường hoàn toàn mới, một nơi mà chúng ta có thể nhìn thấy, nghe thấy, cảm nhận được bằng xúc giác và khứu giác.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Sau cùng, Kurzweil tin rằng loài người sẽ chạm tới một ngưỡng mà chúng ta sẽ <em>hoàn toàn</em> là nhân tạo; một thời điểm mà khi nhìn vào các vật liệu sinh học và nghĩ rằng có một thời loài người đã mông muội <em>đến mức không tưởng</em> khi từng được tạo ra bởi <em>những thứ đó</em>; một thời điểm khi mà chúng ta đọc về những trang đầu tiên trong lịch sử nhân loại khi mà vi khuẩn, tai nạn, dịch bệnh hay lão hóa có thể <em>giết</em> người ta dù người ta không muốn; một thời điểm mà cuộc cách mạng AI có thể kết thúc khi con người và AI hòa làm một. Đây là cách mà Kurzweil vẽ ra về việc con người sẽ chinh phục hoàn toàn sinh học và trở nên vĩnh cửu và bền chắc – đây là cái nhìn của ông về phía bên kia của chùm thăng bằng. Và ông tin rằng chúng ta sẽ đến được đó. Sớm thôi.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Bạn có lẽ sẽ không ngạc nhiên khi biết rằng ý tưởng của Kurzweil đã vấp phải rất nhiều chỉ trích. Dự đoán của ông về năm 2045 cho mốc dị biệt và khả năng sống vĩnh cửu theo sau đó của con người đã bị mỉa mai như là “lời kêu gào của lũ mọt sách”, hay là “thiết kế thông minh cho những người IQ 140.” Những người khác đặt câu hỏi cho dòng thời gian quá sức lạc quan của ông, hay mức hiểu biết của ông về bộ não và cơ thể người, hay ứng dụng của ông về định luật Moore, trong khi định luật này thường được áp dụng vào những tiến bộ trong phần cứng, thì ông lại đem nó áp dụng vào rất nhiều thứ khác bao gồm cả phần mềm. Cứ mỗi chuyên gia tin tưởng nhiệt liệt rằng Kurzweil là chân lý thì có tới ba người cho rằng ông đã đi quá xa.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng điều làm tôi ngạc nhiên là phần lớn các chuyên gia không đồng tình với Kurzweil <em>không hẳn </em>bất đồng với toàn bộ những gì ông cho là có khả năng. Đọc về một tầm nhìn kỳ dị đến vậy về tương lai, tôi trông chờ những người phản đối nói rằng, “Đương nhiên chuyện đó là không thế,” nhưng thay vào đó họ lại nói rằng, “Ừ, đúng là tất cả những chuyện đó có thể xảy ra nếu như chúng ta có thể chuyển đổi an toàn sang ASI, nhưng đó mới là phần khó.” Bostrom, một trong những tiếng nói đáng chú ý nhất trong việc cảnh báo chúng ta về nguy cơ của AI, vẫn công nhận rằng:</span></p> 
<table> 
 <tbody> 
  <tr> 
   <td width="638"><span style="color: #0000ff;"><em>R</em><em>ấ</em><em>t khó đ</em><em>ể</em><em> nghĩ ra đ</em><em>ượ</em><em>c b</em><em>ấ</em><em>t kỳ v</em><em>ấ</em><em>n đ</em><em>ề</em><em> nào mà m</em><em>ộ</em><em>t siêu trí tu</em><em>ệ</em><em> không th</em><em>ể</em><em> ho</em><em>ặ</em><em>c gi</em><em>ả</em><em>i quy</em><em>ế</em><em>t đ</em><em>ượ</em><em>c ho</em><em>ặ</em><em>c ít nh</em><em>ấ</em><em>t là giúp chúng ta gi</em><em>ả</em><em>i quy</em><em>ế</em><em>t. B</em><em>ệ</em><em>nh d</em><em>ị</em><em>ch, đói nghèo, phá h</em><em>ủ</em><em>y môi tr</em><em>ườ</em><em>ng, nh</em><em>ữ</em><em>ng s</em><em>ự</em><em> ch</em><em>ị</em><em>u đ</em><em>ự</em><em>ng không c</em><em>ầ</em><em>n thi</em><em>ế</em><em>t v</em><em>ề</em><em> m</em><em>ọ</em><em>i m</em><em>ặ</em><em>t: đó là nh</em><em>ữ</em><em>ng th</em><em>ứ</em><em> mà m</em><em>ộ</em><em>t siêu trí tu</em><em>ệ</em><em> đ</em><em>ượ</em><em>c trang b</em><em>ị</em><em> công ngh</em><em>ệ</em><em> nano có kh</em><em>ả</em><em> năng xóa b</em><em>ỏ</em><em>. Thêm vào đó, m</em><em>ộ</em><em>t siêu trí tu</em><em>ệ</em><em> s</em><em>ẽ</em><em> có th</em><em>ể</em><em> cho chúng ta m</em><em>ộ</em><em>t cu</em><em>ộ</em><em>c đ</em><em>ờ</em><em>i vô h</em><em>ạ</em><em>n, có th</em><em>ể</em><em> b</em><em>ằ</em><em>ng cách ho</em><em>ặ</em><em>c d</em><em>ừ</em><em>ng l</em><em>ạ</em><em>i ho</em><em>ặ</em><em>c đ</em><em>ả</em><em>o ng</em><em>ượ</em><em>c lão hóa b</em><em>ằ</em><em>ng cách dùng d</em><em>ượ</em><em>c li</em><em>ệ</em><em>u nano, hay b</em><em>ằ</em><em>ng cách cho chúng ta l</em><em>ự</em><em>a ch</em><em>ọ</em><em>n nâng c</em><em>ấ</em><em>p b</em><em>ả</em><em>n thân. Siêu trí tu</em><em>ệ</em><em> cũng có th</em><em>ể</em><em> t</em><em>ạ</em><em>o ra nh</em><em>ữ</em><em>ng c</em><em>ơ</em><em> h</em><em>ộ</em><em>i đ</em><em>ể</em><em> nâng cao năng l</em><em>ự</em><em>c trí tu</em><em>ệ</em><em> và c</em><em>ả</em><em>m xúc, và có th</em><em>ể</em><em> giúp chúng ta t</em><em>ạ</em><em>o nên m</em><em>ộ</em><em>t th</em><em>ế</em><em> gi</em><em>ớ</em><em>i th</em><em>ử</em><em> nghi</em><em>ệ</em><em>m vô cùng lôi cu</em><em>ố</em><em>n trong đó chúng ta có th</em><em>ể</em><em> s</em><em>ố</em><em>ng c</em><em>ả</em><em> đ</em><em>ờ</em><em>i ch</em><em>ỉ</em><em> đ</em><em>ể</em><em> ch</em><em>ơ</em><em>i </em><em>đ</em><em>i</em><em>ệ</em><em>n t</em><em>ử</em><em>, quan tâm t</em><em>ớ</em><em>i ng</em><em>ườ</em><em>i khác, tr</em><em>ả</em><em>i nghi</em><em>ệ</em><em>m, phát tri</em><em>ể</em><em>n b</em><em>ả</em><em>n thân, và s</em><em>ố</em><em>ng g</em><em>ầ</em><em>n nh</em><em>ấ</em><em>t v</em><em>ớ</em><em>i lý t</em><em>ưở</em><em>ng c</em><em>ủ</em><em>a chúng ta.</em></span></td> 
  </tr> 
 </tbody> 
</table> 
<p style="text-align: justify;">&nbsp;</p> 
<p style="text-align: justify;"><span style="color: #000000;">Đây là một trích dẫn từ một nhân vật <em>không hề </em>nằm trong Góc Tự Tin, nhưng lại là điều tôi thường bắt gặp – những chuyên gia nhăn nhó ra mặt với Kurzweil vì cả tá lý do nhưng lại không cho rằng điều ông nói là bất khả <em>nếu như</em> chúng ta có thể an toàn tiến tới ASI. Đó là lý do tôi thấy ý tưởng của Kurzweil có tính lan truyền rất lớn – bởi vì nó giãi bày phần tươi sáng của câu chuyện và nó hoàn toàn là có thể. <em>Nếu như nó là một vị Chúa tốt.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Chỉ trích lớn nhất tôi thấy đối với những người nằm trong Góc Tự tin là họ có thể <em>sai lầm một cách nguy hiểm</em> khi đánh giá những mặt trái của ASI. Cuốn sách nổi tiếng của Kurzweil <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.amazon.com/gp/product/0143037889/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0143037889&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=54Q62R5PYJBEENTP"><em>Điểm dị biệt đang tới gần</em></a></strong></span> dài tới 700 trang, và ông dành khoảng 20 trang trong số đó cảnh báo về những nguy cơ tiềm tàng. Tôi đã nhắc tới ở đoạn trước rằng số phận của chúng ta khi sức mạnh mới khủng khiếp này trỗi dậy phụ thuộc vào việc nó nằm trong tay ai và mục đích của họ là gì. Kurzweil trả lời cả hai phần của câu hỏi này một cách gọn gàng rằng, “[ASI] nổi lên nhờ rất nhiều nỗ lực đa dạng và sẽ được kết hợp sâu sắc vào cấu trúc nền văn minh của chúng ta. Thực tế là, nó sẽ gắn liền mật thiết với cơ thể và bộ não của chúng ta. Vì vậy, nó sẽ phản ánh giá trị của chúng ta vì nó chính là chúng ta.”</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng nếu đó là câu trả lời, tại sao quá nhiều trong số những người thông minh nhất thế giới lại trở nên lo lắng như vậy? Tại sao Stephen Hawking <a style="color: #000000;" href="https://www.washingtonpost.com/news/speaking-of-science/wp/2014/12/02/stephen-hawking-just-got-an-artificial-intelligence-upgrade-but-still-thinks-it-could-bring-an-end-to-mankind/">nói</a> rằng sự phát triển của ASI&nbsp; “có thể đánh dấu cho sự chấm dứt của nhân loại” và Bill Gates <a style="color: #000000;" href="https://www.washingtonpost.com/blogs/the-switch/wp/2015/01/28/bill-gates-on-dangers-of-artificial-intelligence-dont-understand-why-some-people-are-not-concerned/">nói</a> rằng ông không “hiểu nổi tại sao lại có những người hoàn toàn không quan tâm” và Elon Musk<span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.theguardian.com/technology/2014/oct/27/elon-musk-artificial-intelligence-ai-biggest-existential-threat"> lo ngại</a></strong></span> rằng chúng ta đang “triệu hồi ác quỷ”? Và tại sao nhiều chuyên gia về lĩnh vực này gọi ASI là hiểm họa lớn nhất cho nhân loại? Những người này, và các nhà tư tưởng khác trên Đường E Ngại, không hề tin vào những lời phủi đi nguy cơ của AI của Kurzweil. Họ vô cùng, <em>vô cùng</em> lo ngại về cuộc Cách mạng Trí tuệ nhân tạo, và họ không tập trung vào phía vui vẻ của chùm thăng bằng. Họ còn bận nhìn về phía bên kia, nơi họ thấy một tương lai khủng khiếp, mà họ không chắc rằng liệu chúng ta có thể tránh khỏi hay không.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">—</span></p> 
<h2 style="text-align: justify;"><span style="color: #000000;"><strong>Tại sao tương lai có thể là cơn ác mộng khủng khiếp nhất của chúng ta</strong></span></h2> 
<p style="text-align: justify;"><span style="color: #000000;">Một trong những lý do tôi muốn tìm hiểu về AI là chủ đề về “robot xấu xa” luôn làm tôi bối rối. Tất cả những bộ phim về robot ác luôn có cảm giác vô thực, và tôi không hoàn toàn hiểu nổi làm thế nào mà có một tình huống ngoài đời thực mà AI có thể thật sự nguy hiểm. Robot được tạo ra bởi <em>chúng ta</em>, vậy tại sao chúng ta lại có thể thiết kế chúng theo cách mà có thể gây ra bất kỳ tiêu cực gì chứ? Không phải là chúng ta sẽ tạo ra hàng tá những cơ chế đề phòng sao? Tại sao một robot lại thậm chí muốn làm điều gì xấu chứ? Tại sao một robot lại có thể có “ham muốn” <em>bất kỳ điều gì</em> chứ? Tôi đã từng rất nghi ngờ. Nhưng rồi tôi cứ nghe thấy rất nhiều người thông minh nói về điều đó…</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Những người này thường nằm đâu đó trong khoảng này:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Square42-1024x1012.jpg"><img class="img-responsive" src="https://i2.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Square42-1024x1012.jpg" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Những người trong Đường E Ngại không sống trong Thảo nguyên Hoảng loạn hay là Đồi Tuyệt vọng – cả hai nơi đó nằm ở rất xa phía bên trái của biểu đồ – nhưng họ vẫn hết sức lo lắng và cực kỳ căng thẳng. Nằm ở giữa biểu đồ không có nghĩa là bạn cho rằng sự trỗi dậy của ASI sẽ là một điều <em>tầm tầm</em> – những người theo trường phái này có hẳn một khu của riêng họ – mà có nghĩa là bạn nghĩ tới <em>cả hai chiều</em>, bao gồm những hệ quả cực kỳ tốt và cả cực kỳ tệ, đều có thể xảy ra nhưng bạn chưa chắc được rằng cái nào mới đúng.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Một phần những người này tràn đầy háo hức về những điều mà Trí tuệ nhân tạo có thể làm cho chúng ta – chỉ là họ lo lắng chút đỉnh rằng đây sẽ là phần mở đầu của <em>Chiếc rương Thánh tích </em>(Raiders of Lost Ark) và nhân loại là anh chàng này:</span></p> 
<p><span style="color: #000000;"><img class="img-responsive" style="display: block; margin-left: auto; margin-right: auto;" src="https://i2.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/raiders1.jpg" alt="raiders"></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Và trong khi anh ta đứng đó, hoàn toàn hài lòng với cái roi và thần tượng&nbsp;của anh ta, nghĩ rằng anh ta đã biết hết mọi thứ, và anh ta quá cao hứng khi thốt lên câu thoại “Adios Señor”, và rồi bỗng nhiên anh ta bớt hài lòng hơn nhiều vì điều này xảy ra:</span></p> 
<p><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/500px-Satipo_death-300x225.jpg"><img class="img-responsive" style="display: block; margin-left: auto; margin-right: auto;" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/500px-Satipo_death-300x225.jpg" alt=""></a></span></p> 
<p style="text-align: center;"><span style="color: #000000;">(Xin lỗi)</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Trong khi đó, Indiana Jones, người hiểu biết và thận trọng hơn, hiểu rõ những nguy hiểm và cách để né tránh chúng, đã thoát ra khỏi hang động một cách an toàn. Và trong khi tôi nghe những người trên Đường E Ngại nói về AI, nghe cứ như thể họ muốn nói, “Ừm chúng ta đang giống như thằng cha đầu tiên nhưng thay vào đó chúng ta có lẽ nên cố gắng hết sức để trở thành như Indiana Jones.”</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy điều gì làm cho những người cư ngụ trên Đường E Ngại cảm thấy e ngại?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Đầu tiên thì, nói chung là, khi nói tới việc phát triển AI siêu thông minh, chúng ta đang tạo ra một thứ có thể thay đổi mọi thứ, nhưng lại nằm trong một lĩnh vực hoàn toàn chưa bao giờ có trước đây, và chúng ta chẳng biết được điều gì sẽ xảy ra khi chúng ta đạt tới đó. Nhà khoa học Danny Hillis so sánh những điều đang xảy ra với cái ngưỡng khi mà “những cơ chế đơn bào biến thành các cơ chế đa bào. Chúng ta là những con Amip và chúng ta không thể nào biết nổi thứ chúng ta đang tạo ra là cái quái gì.” (14) Nick Bostrom lo rằng tạo nên một thứ gì đó thông minh hơn bản thân là một lỗi tiến hóa cơ bản, và so sánh nỗi hào hứng về điều này như những con sẻ nhận nuôi một con cú con để nó giúp đỡ và bảo vệ chúng khi nó lớn lên – trong lúc lờ đi những tiếng kêu hoảng hốt của những con sẻ khác do nỗi lo lắng rằng liệu đó có phải một ý hay không… (15)</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Và khi bạn gộp cụm “lĩnh vực hoàn toàn chưa bao giờ có trước đây, chưa được hiểu rõ” và “điều này sẽ mang lại tác động to lớn khi nó diễn ra,” bạn đã mở ra cánh cửa dẫn tới hai từ đáng sợ nhất trong tiếng Anh:</span></p> 
<h2 style="text-align: justify;"><span style="color: #000000;"><em>Nguy cơ tuyệt chủng </em>(Existential risk).</span></h2> 
<p style="text-align: justify;"><span style="color: #000000;">Một nguy cơ tuyệt chủng là thứ sẽ đem lại hệ quả hết sức nặng nề và lâu dài cho nhân loại. Thường thì nguy cơ tuyệt chủng có nghĩa chính là tuyệt chủng. Thử xem xét biểu đồ sau từ một <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://www.youtube.com/watch?v=pywF6ZzsghI">bài phát biểu tại Google</a></strong></span> bởi Bostrom:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Existential-Risk-Chart-600x600.jpg"><img class="img-responsive" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Existential-Risk-Chart-600x600.jpg" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Bạn có thể nhìn thấy nhãn “nguy cơ tuyệt chủng” được dành cho một thứ trải dài quá mức loài, trải qua mức thế hệ (tức là nó là vĩnh cửu) và nó tạo ra hệ quả hoặc vô cùng nghiêm trọng hoặc là gây ra cái chết. Về mặt kỹ thuật, nó bao gồm một tình huống mà toàn loài người luôn luôn ở trong tình trạng chịu đựng hay bị tra tấn, nhưng lần nữa, chúng ta thường dùng nó để nói về tuyệt chủng. Có ba thứ có thể gây cho nhân loại một thảm họa tuyệt chủng.</span></p> 
<ul style="text-align: justify;"> 
 <li><span style="color: #000000;"><strong>Tự nhiên</strong> – một vụ va chạm thiên thạch lớn, một sự thay đổi trong khí quyển làm không khí không còn phù hợp cho sự sống, một vi rút chết người hay một bệnh do vi khuẩn gây ra quét sạch toàn thế giới, v.v.</span></li> 
 <li><span style="color: #000000;"><strong>Người ngoài hành tinh – </strong>đây là điều mà Stephen Hawking, Carl Sagan, và rất nhiều nhà thiên văn khác lo ngại khi họ <a style="color: #000000;" href="http://waitbutwhy.com/2014/05/fermi-paradox.html">khuyên</a> METI nên dừng việc phát sóng những tín hiệu liên lạc ra ngoài vũ trụ. Họ không muốn chúng ta biến thành người Anh điêng bản xứ và cho những kẻ xâm lược châu Âu biết rằng chúng ta đang ở đây.</span></li> 
 <li><span style="color: #000000;"><strong>Con người – </strong>những kẻ khủng bố nắm được trong tay một vũ khí gây diệt chủng, một cuộc chiến tranh thảm họa toàn cầu, hay là loài người tạo ra một thứ gì đó thông minh hơn bản thân họ một cách vội vã mà không nghĩ thấu đáo về nó trước…</span></li> 
</ul> 
<p style="text-align: justify;"><span style="color: #000000;">Bostrom chỉ ra rằng nếu số 1 và số 2 chưa thể quét sạch chúng ta trong 100,000 năm đầu tiên, thì có lẽ nó cũng sẽ không xảy ra trong thế kỷ này.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Điều số 3 thì lại làm cho ông sợ hãi. Ông mô tả bằng một ẩn dụ như một cái hũ với những hòn đá cuội trong đó. Cho là phần lớn những hòn đá đều màu trắng, một nhóm nhỏ hơn là màu đỏ, còn một phần rất nhỏ là màu đen. Mỗi lần nhân loại phát minh ra một thứ mới cũng như rút một hòn đá ra khỏi cái hũ. Phần lớn các phát minh là trung dung hay có lợi cho loài người – đó là những viên đá trắng. Một số có hại, như vũ khí hủy diệt hàng loạt – nhưng chúng không gây ra thảm họa diệt chủng – những viên màu đỏ. Nếu chúng ta có bao giờ sáng tạo ra thứ gì đẩy chúng ta tới bờ vực tiệt chủng, đó sẽ là kéo ra viên đá đen hiếm hoi. Chúng ta chưa rút ra phải viên đá đen nào – bạn có thể biết điều đó bởi vì bạn đang sống và đọc bài viết này. Nhưng Bostrom không nghĩ rằng không có khả năng rút phải một viên trong tương lai gần sắp tới. Nếu như, ví dụ như vũ khí hạt nhân, lại có thể được chế tạo một cách <em>dễ dàng</em> thay vì vô cùng khó khăn và phức tạp, thì những kẻ khủng bố đã đánh bom cho nhân loại về lại thời đồ đá từ lâu rồi. Bom hạt nhân không phải là một viên đá đen <em>nhưng nó cũng không khác là bao lăm.</em> Bostrom tin rằng ASI chính là ứng cử viên hàng đầu cho viên đá đen đó.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy là bạn sẽ nghe thấy rất nhiều điều tệ hại mà ASI có thể đem tới – thất nghiệp tăng cao khi AI lấy đi ngày càng nhiều việc làm hơn, dân số loài người phình ra nếu như chúng ta có thể tìm ra cách chống lão hóa, v.v. Nhưng điều duy nhất chúng ta cần phải ngẫm nghĩ thật sâu sắc là về <em>mối quan tâm lớn nhất</em>: nguy cơ tuyệt chủng.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy điều này dẫn chúng ta tới một câu hỏi trọng tâm mà chúng ta đã đề cập tới trong phần trước&nbsp;của bài viết này. <strong>Khi ASI nổi lên, ai hay cái gì sẽ nắm giữ quyền lực khổng lồ mới mẻ này, và động cơ của họ sẽ là gì?</strong></span></p> 
<p>&nbsp;</p> 
<p>Đọc 6 phần ở đây:</p> 
<h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-con-duong-toi-sieu-tri-tue-phan-1">Cuộc cách mạng trí tuệ nhân tạo: Con đường tới Siêu trí tuệ (Phần 1)</a></span></h4> 
<h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-con-duong-toi-sieu-tri-tue-phan-2">Cuộc cách mạng trí tuệ nhân tạo: Con đường tới Siêu trí tuệ (Phần 2)</a></span></h4> 
<h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung-phan-3">Cuộc cách mạng trí tuệ nhân tạo: Nhân loại sẽ trở nên bất tử hay diệt chủng? (Phần 3)</a></span></h4> 
<h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung-phan-4">Cuộc cách mạng trí tuệ nhân tạo: Nhân loại sẽ trở nên bất tử hay diệt chủng? (Phần 4)</a></span></h4> 
<div class="composs-main-article-head"> 
 <h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung-phan-5">Cuộc cách mạng trí tuệ nhân tạo: Nhân loại sẽ trở nên bất tử hay diệt chủng? (Phần 5)</a></span></h4> 
 <div class="composs-main-article-head"> 
  <h4><span style="color: #0000ff;"><a style="color: #0000ff;" href="/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung-phan-6">Cuộc cách mạng trí tuệ nhân tạo: Nhân loại sẽ trở nên bất tử hay diệt chủng? (Phần 6)</a></span></h4> 
 </div> 
</div> 
<p><strong>Dịch</strong>:&nbsp;<a href="https://liemaximun1208.wordpress.com/2017/03/16/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung/">https://liemaximun1208.wordpress.com/2017/03/16/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung/</a></p> 
<p><strong>Nguồn</strong>:&nbsp;<a href="http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html">http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html</a></p>