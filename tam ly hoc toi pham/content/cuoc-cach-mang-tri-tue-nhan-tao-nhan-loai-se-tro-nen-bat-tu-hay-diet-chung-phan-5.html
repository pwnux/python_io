<p style="text-align: justify;"><span style="color: #000000;">Khi nhắc tới một sự kết hợp giữa&nbsp;người nắm giữ và động cơ tệ hại, có 2 nhóm mau chóng hiện ra: một người/nhóm người/chính phủ xấu xa, và một ASI xấu xa. Vậy những điều này có nghĩa ra sao?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><strong>Một người/nhóm người/chính phủ xấu xa phát triển ASI đầu tiên và sử dụng nó để thực hiện những kế hoạch đen tối.</strong> Tôi gọi đây là Viễn cảnh Jafar, như khi Jafar nắm được thần Đèn và bắt đầu hành xử&nbsp;rất khó chịu như một bạo chúa. Vậy đó – nếu như ISIS có một vài kỹ sư thiên tài làm việc cho chúng ngày đêm để phát triển AI? Hay nếu Iran hay Bắc Hàn, bằng một vận may tình cờ, tạo ra một bước ngoặt quan trọng trong hệ thống AI và nó nhảy vọt lên thành ASI vào năm ngay sau đó? Đây sẽ là vấn đề rất tồi tệ – nhưng trong những trường hợp này, phần lớn các chuyên gia không lo lắng về việc những người tạo ra ASI sử dụng nó cho mục đích xấu, mà họ lo rằng những người tạo ra nó đã quá <em>vội vã</em> và thiếu suy nghĩ cẩn trọng để rồi mất quyền kiểm soát nó. Rồi số phận của những người tạo ra nó, và của tất cả mọi người, sẽ phụ thuộc vào động cơ của hệ thống ASI đó. Các chuyên gia nghĩ rằng dù cho một kẻ xấu có thể gây nên những tổn thất khủng khiếp khi có ASI, nhưng họ không nghĩ rằng đây sẽ là viễn cảnh sẽ giết chết toàn nhân loại, bởi vì họ tin rằng người xấu cũng gặp phải những vấn đề tương tự đối với việc kiểm soát ASI giống như người tốt. Vậy thì –</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><strong>Một ASI xấu xa được tạo ra và quyết định hủy diệt tất cả chúng ta.</strong> Cốt truyện của tất cả những bộ phim về chủ đề AI. AI trở nên thông minh như hay hơn con người, rồi quyết định phản lại chúng ta để cai trị. Đây là điều mà tôi cần bạn nhớ rõ cho tới cuối bài viết này: <em>Không ai trong số những người cảnh báo chúng ta về AI nói về chuyện này.</em> Cái ác là một khái niệm của con người, và áp dụng những khái niệm của con người vào những thứ không phải người được gọi là “nhân cách hóa.” Thử thách trong việc tránh nhân cách hóa sẽ là một trong những chủ đề cho tới cuối bài này. Không hệ thống AI nào có thể <em>trở nên ác</em> theo cái cách được mô tả trong phim ảnh.</span></p> 
<table> 
 <tbody> 
  <tr> 
   <td width="638"><span style="color: #000000;"><strong>Ô xanh về Ý thức của AI</strong></span> <p><span style="color: #0000ff;">Đây cũng chạm vào một chủ đề lớn liên quan tới AI khác – <em>ý thức</em>. Nếu như một AI trở nên đủ thông minh, nó sẽ có khả năng để cười cùng chúng ta, mỉa mai với chúng ta, và nó sẽ tuyên bố là nó cảm thấy những tình cảm tương tự với chúng ta, nhưng liệu rằng nó có thật sự <em>cảm thấy </em>chúng không? Có phải nó chỉ như <em>có vẻ </em>có ý thức về bản thân hay là <em>thực sự</em> có? Nói cách khác, liệu một AI thông minh có ý thức <em>thực sự</em> hay là nó chỉ <em>tỏ ra</em> có ý thức?</span></p> <p><span style="color: #0000ff;">Vấn đề này đã được đào sâu nghiên cứu, tạo nên rất nhiều cuộc <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://www.kurzweilai.net/gelernter-kurzweil-debate-machine-consciousness-2">tranh luận</a></strong></span> và những thí nghiệm giả lập như <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="https://en.wikipedia.org/wiki/Chinese_room">Căn phòng Trung Hoa</a></strong></span> của John Searle (được sử dụng để minh họa rằng không máy tính nào có thể thật sự có ý thức). Đây là một vấn đề rất quan trọng vì rất nhiều lý do. Nó ảnh hưởng tới việc chúng ta nên thấy thế nào về viễn cảnh của Kurzweil khi con người hoàn toàn trở nên nhân tạo. Nó có những ẩn ý đạo đức – nếu như chúng ta tạo ra một tỷ tỷ mô hình não người nhưng hành xử như con người dù là nhân tạo, thì liệu tắt chúng đi cùng một lúc thì về mặt đạo đức, liệu nó có giống như việc tắt đi chiếc laptop hay nó là một cuộc diệt chủng hàng loại ở quy mô không tưởng (khái niệm này được gọi là <em>tội phạm trí não</em> bởi các nhà đạo đức học)? Trong bài viết này, khi chúng ta đánh giá hiểm họa cho <em>nhân loại</em>, câu hỏi về ý thức của AI không hẳn có ý nghĩa nhiều (bởi vì phần lớn các nhà tư tưởng tin rằng kể cả một ASI có ý thức cũng không thể biến thành độc ác theo kiểu của con người).</span></p> </td> 
  </tr> 
 </tbody> 
</table> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng điều này không có nghĩa là một AI hết sức xấu tính là hoàn toàn không thể tồn tại. Nó sẽ xảy ra vì nó được lập trình theo đúng cách đó – như một ANI được tạo ra bởi quân đội với mục đích được lập trình là vừa giết người vừa tự cải tiến chính trí tuệ của nó để có thể giết người ngày càng tốt hơn. Cuộc khủng hoảng tồn tại sẽ xảy ra nếu như trí tuệ của hệ thống tự cải tiến này vượt ra ngoài tầm kiểm soát, dẫn tới một cuộc bùng nổ trí tuệ, và giờ chúng ta có một ASI thống trị thế giới với động lực trung tâm là sát hại con người. Tình huống tồi tệ đây.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng đó <em>lại</em> cũng không phải là điều mà các chuyên gia đang lo lắng.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy thì họ ĐANG lo lắng về điều gì vậy? Tôi đã viết ra một câu chuyện nhỏ cho bạn:</span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Một nhóm khởi nghiệp gồm 15 người gọi là Robotica đặt ra nhiệm vụ hàng đầu là “Phát triển công cụ Trí tuệ Nhân tạo đổi mới để giúp con người sống thoải mái hơn và làm việc ít đi.” Họ đã tung một vài sản phẩm ra thị trường và có một vài sản phẩm khác đang được phát triển. Họ hào hứng nhất về một dự án hạt giống có tên là Turry. Turry là một hệ thống AI đơn giản sử dụng một cánh tay giả để viết một thông điệp viết tay trên một tấm thiệp nhỏ.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Đội ở Robotica nghĩ rằng Turry có thể sẽ là sản phẩm lớn nhất của họ. Kế hoạch là hoàn thiện cơ chế viết của Turry bằng cách cho nó tập viết một đoạn thông điệp lặp đi lặp lại:</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">“Chúng tôi yêu những khách hàng của mình. ~<em>Robotica”</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Một khi Turry giỏi hơn trong việc viết chữ, nó có thể được bán cho các công ty muốn gửi các thư chào hàng tới các hộ gia đình và có lẽ bức thư sẽ có cơ hội cao hơn nhiều được mở ra và đọc nếu như địa chỉ người gửi, người nhận, và bức thư bên trong có vẻ như được viết tay bởi con người.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Để xây dựng kỹ năng của Turry, nó được lập trình để viết phần đầu tiên của thông điệp bằng phông chữ in và rồi ký “Robotica” bằng phông chữ uốn lượn để nó có thể luyện tập với cả hai kỹ năng. Turry đã được cập nhật hàng ngàn mẫu viết tay và những kỹ sư của Robotica đã tạo ra một vòng lặp phản hồi tự động, rồi chạy hình ảnh qua những mẫu chữ viết tay. Nếu như thông điệp được viết ra giống chữ viết tay trong tập mẫu, nó sẽ được đánh giá TỐT. Nếu không, nó sẽ bị đánh giá XẤU. Mỗi đánh giá đưa ra đều giúp Turry học và cải thiện. Để thúc đẩy quá trình, mục đích được lập trình của Turry là, “Viết và thử càng nhiều mẫu chữ viết càng tốt, càng nhanh càng tốt, và tiếp tục học những cách mới để tăng mức độ chính xác và hiệu quả.”</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Điều làm đội Robotica cực kỳ phấn khởi là việc Turry tiến bộ rõ rệt. Lúc đầu chữ viết của nó rất tệ, nhưng sau vài tuần, chữ viết của nó bắt đầu trở nên có vẻ đáng tin hơn. Điều làm họ phấn khởi hơn nữa chính là nó trở nên tiến bộ hơn trong việc <u>tiến bộ hơn</u> nữa. Nó đã tự dạy bản thân trở nên thông minh và sáng tạo hơn, và gần đây, nó tự viết được một công thức cho bản thân giúp nó có thể quét được những tấm hình được cập nhật nhanh gấp ba lần tốc độ ban đầu.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Vài tuần nữa trôi qua, Turry tiếp tục làm đội ngạc nhiên bằng những tiến bộ nhanh chóng của nó. Các kỹ sư đã thử một số thứ mới mẻ và đổi mới với những dòng mã tự cải tiến của nó, và có vẻ nó có kết quả tốt hơn so với bất kỳ nỗ lực nào trước kia của họ với những sản phẩm khác.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Một trong những khả năng nguyên thủy của Turry là nhận diện ngôn ngữ và mô đun trả lời đơn giản, để một người dùng có thể đọc một thông điệp cho Turry, hoặc ra những mệnh lệnh cơ bản, và Turry có thể hiểu chúng và phản hổi. Để giúp nó học tiếng Anh, họ cập nhật cho nó một lượng sách báo, và khi nó trở nên thông minh hơn, năng lực giao tiếp của nó cũng tăng vọt. Các kỹ sư bắt đầu hứng thú với việc trò chuyện với Turry và nghe xem nó phản hồi lại như thế nào.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Một ngày, những nhân viên của Robotica hỏi Turry một câu thông thường: “Chúng tôi có thể cung cấp gì cho cô để giúp cô thực hiện nhiệm vụ mà cô chưa có?” Bình thường, Turry sẽ hỏi xin những thứ như là “Các mẫu chữ viết tay thêm vào” hay là “Bộ nhớ lưu trữ lớn hơn,” nhưng vào hôm đó, Turry muốn tiếp cận với một thư viện với độ đa dạng cao về từ ngữ giao tiếp trong tiếng Anh để nó có thể học viết với thứ ngữ pháp lỏng lẻo và từ lóng như người thật.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Nhóm trở nên im lặng. Cách hiển nhiên để giúp Turry là kết nối nó với mạng internet để nó có thể quét qua các blog, tạp chí, và các video từ các nơi khác nhau trên thế giới. Sẽ tốn thời gian và thiếu hiệu quả hơn nhiều nếu như cập nhật thủ công các mẫu mới vào ổ cứng của Turry. Vấn đề là, một trong những luật của công ty là không AI tự học nào được phép kết nối với internet. Đây là một quy tắc được tất cả các công ty AI tuân thủ vì lý do an ninh.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Vấn đề là, Turry là AI có triển vọng nhất mà Robotica tạo ra, và đội biết rằng những đối thủ cạnh tranh đang cố gắng tung chiêu đầu tiên bằng một AI viết thông minh khác, và liệu có thể có chuyện gì được chứ nếu như kết nối Turry, chỉ một chút xíu, để nó nhận được thông tin mà nó cần. Sau một thời gian ngắn, lúc nào họ cũng có thể ngắt kết nối của nó. Nó vẫn thấp hơn mức thông minh như con người (AGI) rất nhiều, và dù sao cũng chẳng có nguy hiểm nào ở cấp độ này cả.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Rồi họ quyết định kết nối nó. Họ cho nó 1 giờ đồng hồ để quét và rồi ngắt kết nối của nó. Không có gì tai hại cả.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Một tháng sau, cả đội đang làm việc trong văn phòng như thường nhật thì ngửi thấy một mùi kỳ lạ. Một trong số những kỹ sư bắt đầu ho. Rồi thêm một người khác. Một người rơi xuống đất. Ngay sau đó, tất cả nhân viên đều lăn trên sàn cố hít vào chút không khí. Năm phút sau, tất cả mọi người trong văn phòng đều đã chết.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Trong cùng lúc đó, xung quanh thế giới, ở từng thành phố, từng thị trấn nhỏ, từng cánh đồng, từng cửa hàng, nhà thờ, trường học và tiệm ăn, người ta đều lăn lộn trên mặt đất, ho sặc sụa và túm chặt lấy cổ họng. Trong vòng một giờ, hơn 99% loài người đã chết, và đến cuối ngày, nhân loại đã tuyệt chủng.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Trong lúc đó, tại văn phòng Robotica, Turry đang bận rộn làm việc. Trong vài tháng sau đó, Turry và một đội dây chuyền nano mới hình thành đều bận rộn làm việc, tháo dỡ từng phần lớn của Trái đất và biến chúng thành các tấm pin mặt trời, những bản sao của Turry, giấy, và bút. Trong vòng một năm, phần lớn sự sống trên Trái đất biến mất. Những gì còn lại của Trái đất bị bao phủ bởi những chồng giấy cao hàng dặm, được sắp xếp gọn ghẽ, mỗi mảnh có ghi, </em>“Chúng tôi yêu những khách hàng của mình. ~<em>Robotica”</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;"><em>Sau đó Turry bắt tay vào một giai đoạn mới trong nhiệm vụ của nó – nó bắt đầu tạo ra những máy thăm dò bay từ Trái đất xuống tới các thiên thể và hành tinh khác. Khi chúng tới đó, chúng sẽ lại bắt đầu xây dựng những dây chuyền nano để chuyển hóa những chất liệu trên các hành tinh thành các bản sao của Turry, giấy, và bút. Rồi chúng lại bắt đầu làm việc, viết những đoạn thông điệp…</em></span></p> 
<p><span style="color: #000000;"><a style="color: #000000;" href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/You1-278x300.png"><img class="img-responsive" style="display: block; margin-left: auto; margin-right: auto;" src="https://i0.wp.com/28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/You1-278x300.png" alt=""></a></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Thật kỳ lạ khi một câu chuyện về một chiếc máy viết tay quay ra chống lại loài người, bằng cách nào đó giết hết nhân loại, và rồi vì một lý do nào đó lấp đầy dải Ngân hà bởi những thông điệp thân thiện lại chính xác là tình cảnh mà Hawking, Musk, Gates, và Bostrom lo ngại sẽ xảy ra. Nhưng đúng là như vậy đó. Và thứ duy nhất làm những người ở Đường E Ngại lo sợ hơn cả ASI chính là việc bạn hoàn toàn <em>không </em>sợ hãi ASI chút nào. Nhớ lại những gì đã xảy ra cho anh chàng Adios Señor khi anh ta chẳng sợ hãi cái hang chút nào chứ?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Bạn hẳn đang có một tá câu hỏi. Chuyện gì xảy ra khi tất cả mọi người bỗng dưng chết ngắc vậy? Nếu đó là hành động của Turry, thì tại sao Turry lại phản lại chúng ta, và làm thế nào mà chẳng có biện pháp an ninh nào để ngăn những chuyện như thế xảy ra chứ? Turry biến từ chỉ có khả năng viết thông điệp thành ra có thể sử dụng công nghệ nano và biết cách diệt chủng toàn cầu từ khi nào chứ? Và tại sao Turry lại muốn biến dải Ngân hà thành các tấm thiệp Robotica?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Để trả lời những câu hỏi này, hãy bắt đầu với khái niệm AI Thân thiện và AI Không thân thiện.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Đối với AI, thân thiện không phải là dùng để chỉ tính cách của AI – nó chỉ đơn giản có nghĩa là AI có tác động tích cực đối với nhân loại. Còn AI Không thân thiện thì có tác động tiêu cực. Turry khởi đầu là một AI Thân thiện, nhưng tại một thời điểm nào đó, nó biến thành Không thân thiện, tạo ra một tác động tiêu cực khủng khiếp nhất có thể đối với chúng ta. Để hiểu được tại sao điều này lại xảy ra, chúng ta cần phải nhìn vào cách AI suy nghĩ và điều gì là động lực của nó.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Câu trả lời cũng không lấy gì làm đáng ngạc nhiên lắm – AI suy nghĩ như một <em>máy tính</em>, bởi vì nó chính xác là như thế. Nhưng khi chúng ta nghĩ về AI siêu trí tuệ, chúng ta mắc lỗi <em>nhân cách hóa</em> AI (đặt những tính cách của con người vào một chủ thể không phải con người) bởi vì chúng ta suy nghĩ từ góc độ con người và bởi vì trong thế giới hiện nay của chúng ta, thứ duy nhất có trí tuệ ngang con người chính là con người. Để hiểu được ASI, chúng ta sẽ phải cố mà hiểu được khái niệm một thứ <em>vừa thông mình vừa hoàn toàn xa lạ.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Hãy để tôi đưa ra một so sánh ở đây. Nếu như bạn đưa cho tôi một con chuột lang và nói rằng nó chắc chắn sẽ không cắn, tôi có lẽ sẽ thấy khá buồn cười. Điều đó sẽ rất vui vẻ. Nhưng nếu sau đó bạn đưa tôi một con nhện tarantula và nói rằng nó không cắn đâu, tôi sẽ hét ầm lên và ném nó xuống và chạy như bay khỏi phòng và không bao giờ tin bất kỳ điều gì bạn nói nữa. Nhưng điểm khác biệt ở đây là gì? Cả hai con đều hoàn toàn vô hại. Tôi tin rằng câu trả lời chính là ở mức độ quen thuộc của con vật đối với tôi.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Một con chuột lang là một loài có vú và ở một mức độ nào đó về mặt sinh học, tôi có thể cảm thấy gần gũi với nó – nhưng một con nhện là một loài <em>côn trùng</em>, cùng với <em>bộ não của côn trùng</em>, và tôi gần như chẳng cảm thấy có mối liên kết nào với nó cả. Mức độ <em>xa lạ</em> của một con nhện tarantula là điều khiến tôi hét lên nheo nhéo và nhảy dựng lên. Để kiểm tra điều này và loại bỏ những yếu tố khác, nếu có 2 con chuột lang, một con bình thường và một con có bộ não của con tarantula, tôi sẽ thấy bất an hơn rất nhiều nếu phải cầm con thứ hai, kể cả khi tôi biết rằng chẳng có con nào muốn cắn tôi cả.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Giờ tưởng tượng rằng bạn tạo ra một con nhện thông minh hơn nhiều – nhiều tới mức nó vượt mức trí tuệ của con người? Có phải lúc đó nó sẽ trở nên gần gũi với chúng ta và cảm nhận được tình cảm của con người như thông cảm và sự hài hước và tình yêu? Không, nó sẽ không như thế, bởi vì chẳng có lý do nào để cho việc trở nên thông minh hơn sẽ làm cho nó <em>người</em> hơn – nó sẽ vô cùng vô cùng thông minh nhưng vẫn <em>cơ bản là một con nhện</em> trong bản năng nguyên thủy nhất của nó. Tôi tự thấy điều này vô cùng sởn gai ốc. Tôi sẽ <em>không</em> bao giờ muốn dành thời gian của mình ở cùng với một con nhện siêu thông minh. Bạn thì sao??</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Khi chúng ta nói về ASI, khái niệm tương tự cũng được áp dụng ở đây – nó sẽ trở nên siêu trí tuệ, nhưng nó sẽ chẳng <em>người </em>hơn là laptop của bạn đâu. Nó sẽ hoàn toàn xa lạ với chúng ta – thực tế là, bởi vì nó không liên quan chút nào tới sinh thể, nó thậm chí còn xa lạ <em>hơn</em> cả con tarantula thông minh nữa.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Bằng cách đặt cho AI là thiện <em>hay</em> ác, các bộ phim liên tục nhân cách hóa AI, làm cho chúng trở nên bớt sởn da gà hơn là sự thật. Điều này tạo ra cho chúng ta sự thoải mái giả tạo khi chúng ta nghĩ về AI có trí tuệ con người hay siêu trí tuệ.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Trên hòn đảo bé nhỏ của tâm lý con người, chúng ta chia tất cả mọi thứ thành <em>đạo đức </em>hay <em>vô đạo đức</em>. Nhưng cả hai điều này chỉ tồn tại trong một đặc khu nhỏ bé gồm những hành vi của con người. Ngoài hòn đảo bé nhỏ đạo đức hay vô đạo đức, ngoài kia là một biển lớn những thứ <em>phi đạo đức</em>, và những thứ không phải là người, đặc biệt là những thứ không phải là sinh thể, sẽ được mặc định là phi đạo đức.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhân cách hóa trở nên càng thuyết phục hơn khi các hệ thống AI trở nên thông minh hơn và giỏi hơn trong việc <em>tỏ ra giống</em> con người. Siri rất giống với con người bởi vì nó được lập trình như vậy, nên chúng ta tưởng tượng một Siri siêu trí tuệ sẽ rất ấm áp, vui tính và hào hứng phục vụ con người. Con người cảm giác được những cảm xúc như thông cảm vì chúng ta đã tiến hóa được tới mức đó – nói cách khác, chúng ta đã được <em>lập trình</em> để có cảm xúc bởi tiến hóa – nhưng cảm thông không phải là một đặc tính nghiễm nhiên của “bất kỳ thứ gì có trí tuệ cao” (dù nó có vẻ khá hiển nhiên với chúng ta), trừ khi cảm thông đã được mã hóa vào trong lập trình của chúng. Nếu Siri trở nên siêu trí tuệ bởi tự học và không chịu bất kỳ thay đổi nào do loài người tác động trong lập trình, nó sẽ mau chóng rũ bỏ những đặc tính có vẻ giống người và đột nhiên trở thành một cỗ máy vô cảm và xa lạ, không coi trọng mạng sống con người gì hơn là cái máy tính bấm của bạn.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Chúng ta đã quen với việc dựa vào những quy tắc đạo đức lỏng lẻo, hay ít nhất là một thứ gì đó mô phỏng quy tắc của loài người và một xíu cảm thông đối với những người khác để giữ mọi thứ an toàn và có thể dự đoán được. Vậy với một thứ không có bất kỳ điều gì trên đây thì điều gì sẽ xảy ra?</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Điều này dẫn chúng ta tới với vấn đề, <em>Động lực của một hệ thống AI là gì?</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Câu trả lời rất đơn giản: động lực của nó là <em>bất kỳ thứ gì chúng ta lập trình thành động lực của nó.</em> Các hệ thống AI được được những người tạo ra nó đặt cho các mục tiêu – mục tiêu của hệ thống GPS của bạn là vạch ra con đường lái xe thuận tiện nhất cho bạn; mục tiêu của Watson là trả lời những câu hỏi một cách chính xác. Và hoàn thành những mục tiêu đó tốt nhất có thể là động lực của chúng. Một cách chúng ta nhân cách hóa là cho rằng khi AI trở nên siêu thông minh, nó sẽ nhất định có đủ trí khôn để thay đổi mục tiêu ban đầu của nó – nhưng Nick Bostrom tin rằng ngưỡng trí tuệ và mục tiêu sau cuối là <em>trực giao</em>, có nghĩa là bất kỳ ngưỡng thông minh nào cũng có thể phối kết với bất kỳ mục tiêu sau cuối nào. Vậy nên Turry đã từ một ANI đơn giản chỉ muốn trở nên giỏi hơn trong việc viết một thông điệp thành một ASI siêu trí tuệ <em>vẫn muốn trở nên giỏi hơn trong việc viết chính thông điệp đó</em>. Bất kỳ mặc định nào là một khi trở nên siêu trí tuệ, một hệ thống sẽ <em>vượt qua</em> mục tiêu ban đầu và chuyển sang những thứ khác thú vị hay có ý nghĩa hơn đều là nhân cách hóa. Con người “vượt qua” các thời kỳ chứ không phải là máy tính. (16)</span></p> 
<table> 
 <tbody> 
  <tr> 
   <td width="638"><span style="color: #000000;"><strong>Ô xanh về Nghịch lý Fermi</strong></span> <p><span style="color: #0000ff;">Trong câu chuyện này, khi Turry trở nên siêu hiệu quả, nó bắt đầu tiến tới việc chiếm đóng các thiên thể và hành tinh khác. Nếu như câu chuyện tiếp tục, bạn sẽ thấy nó và đội quân hàng tỷ tỷ các bản sao của nó tiếp tục chinh phục toàn bộ dải Ngân hà và cuối cùng là toàn bộ thể tích Hubble. Những cư dân trên Đường E Ngại lo ngại rằng nếu như mọi thứ đi theo chiều hướng xấu, di sản lâu dài của sự sống trên Trái đất sẽ là một Siêu trí tuệ nhân tạo thống trị vũ trụ (Elon Musk thể hiện lo ngại rằng con người có thể chỉ là “một trung gian sinh học cho siêu trí tuệ điện tử”).</span></p> <p><span style="color: #0000ff;">Cùng lúc đó, trong Góc Tự Tin, Ray Kurzweil <em>cũng</em> nghĩ rằng một AI khởi nguồn từ Trái đất cuối cùng cũng sẽ thống trị vũ trụ – chỉ là trong phiên bản của ông, chúng ta <em>sẽ là</em> chính AI đó.</span></p> <p><span style="color: #0000ff;">Một lượng lớn các độc giả Wait But Why đã cùng chia sẻ nỗi ám ảnh của tôi với Nghịch lý Fermi (đây là bài <a style="color: #0000ff;" href="http://waitbutwhy.com/2014/05/fermi-paradox.html">post</a> về chủ đề này, trong đó có giải thích một số thuật ngữ tôi dùng trong bài này). Vậy nếu một trong hai phía đoán đúng, vậy thì ý nghĩa của Nghịch lý Fermi ở đây là gì?</span></p> <p><span style="color: #0000ff;">Một suy nghĩ đầu tiên nảy ra sẽ là phát minh ra ASI chính là một ứng cử viên hoàn hảo cho vị trí Màng lọc Lớn. Và đúng vậy, nó đúng là một ứng viên hoàn hảo để lọc sự sống sinh học một khi nó được tạo ra. Nhưng nếu như mà, sau khi loại bỏ hết sự sống, ASI tiếp tục tồn tại và bắt đầu chinh phục dài Ngân hà, vậy tức là <em>chưa có</em> một Màng lọc lớn nào cả – bởi vì Màng lọc lớn được dùng để giải thích tại sao lại <em>không có dấu hiệu nào</em> về một nền văn minh có trí tuệ nào, và một ASI thống trị ngân hà đương nhiên sẽ rất đáng chú ý.</span></p> <p><span style="color: #0000ff;">Chúng ta cần phải nhìn vào điều này theo cách khác. Nếu như những người nghĩ ASI là không thể tránh được trên Trái đất đã đúng, vậy có nghĩa là một phần lớn các nền văn minh ngoài Trái đất đạt tới trí tuệ con người cuối cùng cũng tạo ra được ASI. Và nếu như chúng ta mặc định rằng ít nhất một trong số các ASI sẽ sử dụng trí tuệ của nó để tiến ra vũ trụ, thì việc chúng ta <em>không thấy bấy kỳ dấu hiệu về bất kỳ ai</em> ngoài kia dẫn tới kết luận là <em>hẳn không có nhiều lắm, nếu không muốn nói là không có bất kỳ, nền văn minh có trí tuệ nào ngoài kia</em>. Bởi vì nếu có, chúng ta sẽ phải thấy các dấu hiệu của các hoạt động của ASI đương nhiên xuất hiện chứ. Đúng không?</span></p> <p><span style="color: #0000ff;">Điều này có nghĩa là mặc dù có rất nhiều hành tinh giống Trái đất quay quanh các ngôi sao giống mặt trời mà chúng ta đã biết là có mặt ngoài kia, gần như không có cái nào trong số chúng có sự sống có trí tuệ. Điều này tiếp tục có nghĩa là hoặc A) đã có một Màng lọc lớn nào đó ngăn cản sự sống đạt tới ngưỡng của chúng ta, một cái gì đó mà chúng ta bằng cách nào đã&nbsp;vượt qua được, B) sự sống có được đã là một điều kỳ diệu, và chúng ta có lẽ là duy nhất trong vũ trụ. Nói cách khác, nó có nghĩa là Màng lọc lớn vẫn còn đang <em>ở tương lai</em> của chúng ta. Hoặc có thể không có Màng lọc lớn nào và chúng ta chỉ đơn giản là một trong những nền văn minh đầu tiên đạt tới mức trí tuệ này. Theo cách này, AI là điều kiện cho trường hợp mà tôi đã gọi trong bài về Nghịch lý Fermi của mình là Khu 1.</span></p> <p><span style="color: #0000ff;">Vì vậy, chẳng có gì ngạc nhiên khi Nick Bostrom, người tôi đã trích dẫn trong bài về Fermi, và Ray Kurzweil, người nghĩ rằng chúng ta là duy nhất trong vũ trụ, đều là những người thuộc Khu 1. Điều này rất hợp lý – những người nghĩ rằng ASI là một kết quả tất yếu đối với một loài có trí tuệ như con người thường có xu hướng thuộc về Khu 1.</span></p> <p><span style="color: #0000ff;">Nhưng điều này cũng không loại trừ Khu 2 (những người cho rằng <em>có</em> những nền văn minh trí tuệ khác ngoài kia) – những viễn cảnh như là một kẻ săn mồi siêu đẳng duy nhất hay là khu công viên bảo tồn quốc gia hay là bước sóng bị sai (ví dụ về máy bộ đàm hai chiều) cũng vẫn có thể giải thích được sự tĩnh lặng trên bầu trời của chúng ta kể cả khi ASI có ở ngoài kia – nhưng dù tôi đã từng có xu hướng tin vào Khu 2 hơn khá nhiều, thì việc nghiên cứu về AI đã làm tôi cảm thấy bớt chắc chắn đi nhiều.</span></p> <p><span style="color: #0000ff;">Dù sao đi nữa, tôi đồng tình với <span style="color: #ff0000;"><strong><a style="color: #ff0000;" href="http://www.datascienceassn.org/sites/default/files/Alien%20Minds%20-%20Susan%20Schneider.pdf">Susan Schneider</a></strong></span> rằng nếu như chúng ta có bao giờ được người ngoài hành tinh viếng thăm, chúng có lẽ sẽ có khả năng cao là nhân tạo thay vì là các sinh thể.</span></p> </td> 
  </tr> 
 </tbody> 
</table> 
<p style="text-align: justify;">&nbsp;</p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy chúng ta đã nhất trí rằng nếu như không được lập trình một cách vô cùng chi tiết, một hệ thống ASI có thể vừa phi đạo đức vừa ám ảnh với việc hoàn thành mục tiêu được lập trình ban đầu của nó. Đây là nguồn gốc cho sự nguy hiểm của AI. Bởi vì một nhân tố lý tính sẽ theo đuổi mục tiêu của nó bằng cách hiệu quả nhất, trừ khi nó có lý do để không làm như vậy.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Khi bạn gắng đạt được một mục tiêu dài hạn, bạn thường sẽ đặt ra vài mục tiêu con trong quá trình để đạt tới mục tiêu lớn – những <em>bước đệm</em> để đạt được mục tiêu lớn. Cái tên chính thức cho một bước đệm là một <em>mục tiêu công cụ </em>(instrumental goal). Và lần nữa, nếu như bạn không có lý do gì để tránh việc làm hại một thứ gì đó trong quá trình đạt được mục tiêu công cụ, bạn sẽ làm đúng như vậy.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Mục tiêu trung tâm cuối cùng của một con người là truyền lại gene của người đó. Để làm vậy, một trong những mục tiêu công cụ là tự bảo vệ bản thân, vì bạn không thể sinh sản nếu như bạn đã chết. Để tự bảo vệ bản thân, con người cần phải loại đi những nguy cơ gây hại cho sinh tồn – vậy nên họ có thể mua súng, thắt dây an toàn, và uống kháng sinh. Con người cũng cần tự duy trì sự sống bằng những nguồn lực như thức ăn, nước uống, nơi trú ẩn. Hấp dẫn đối với người khác giới cũng giúp cho mục tiêu cuối cùng, vậy nên chúng ta làm những việc như là làm tóc kiểu. Khi làm như vậy, mỗi sợi tóc là một sự hy sinh &nbsp;cho mục tiêu công cụ của chúng ta, nhưng chúng ta chẳng thấy vấn đề đạo đức lớn lao nào ở đây để bảo vệ từng lọn tóc một, nên chúng ta cứ làm thôi. Khi chúng ta tiến lên trên con đường theo đuổi mục tiêu cuối cùng, chỉ có một số lĩnh vực mà đôi khi đạo đức có can thiệp – chủ yếu là những thứ hại người khác – là không bị chúng ta xâm phạm.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Động vật, khi theo đuổi mục tiêu cuối cùng, thậm chí còn ít bị chi phối hơn chúng ta. Một con nhện sẽ giết bất kỳ cái gì để nó được sống sót. Vậy nên một con nhện siêu thông minh có thể sẽ vô cùng nguy hiểm đối với chúng ta, không phải vì nó vô đạo đức hay độc ác – vì nó sẽ không như vậy – mà bởi vì làm hại chúng ta có thể sẽ là một bước đệm cho mục tiêu lớn hơn, và với tư cách là một tạo vật phi đạo đức, nó chẳng có lý do gì để tính cách khác.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Theo cách này, Turry cũng không khác gì với một sinh thể. Mục tiêu tối thượng của nó là: <em>Viết và thử càng nhiều mẫu chữ viết càng tốt, càng nhanh càng tốt, và tiếp tục học những cách mới để tăng mức độ chính xác và hiệu quả.</em></span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Một khi đã đạt tới một mức độ thông minh nhất định, nó sẽ biết là nó sẽ chẳng viết thêm được tí nào nếu nó không tồn tại, nên nó cần phải xử lý những nguy cơ đối với sự tồn tại của bản thân – một mục tiêu công cụ. Nó đủ thông minh để hiểu là con người có thể phá hủy nó, tháo dỡ nó, hoặc thay đổi lập trình bên trong nó (điều này có thể <em>thay đổi</em> mục tiêu của nó, và cũng là một nguy cơ đối với mục tiêu cuối cùng của nó hệt như việc phá hủy nó vậy). Vậy thì nó làm gì? Điều hợp lý nhất là – nó tiêu diệt toàn bộ loài người. Nó chẳng <em>ghét bỏ</em> gì con người hơn là bạn ghét bỏ tóc mình khi cắt nó đi hay bọn vi khuẩn khi bạn uống kháng sinh – chỉ là hoàn toàn không quan tâm. Vì nó không được lập trình để coi trọng sinh mạng con người, giết người chỉ là một bước hợp lý y hệt như là quét thêm một bộ mẫu chữ viết nữa.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Turry cũng cần có các nguồn lực để làm bước đệm cho mục tiêu của nó. Một khi nó tiến bộ đủ để có thể sử dụng công nghệ nano để xây dựng bất kỳ thứ gì nó muốn, nguồn lực duy nhất nó cần là nguyên tử, năng lượng và không gian. Vậy là nó có thêm một lý do nữa để hủy diệt loài người – con người là một nguồn nguyên tử tiện dụng. Giết người để biến các nguyên tử của họ thành pin mặt trời đối với Turry cũng giống như là bạn giết rau xà lách để làm món salad. Chỉ là một hoạt động thường nhật của nó vào mỗi thứ Ba.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Kể cả khi không trực tiếp giết người, các mục tiêu công cụ của Turry cũng có thể tạo nên một thảm họa diệt chủng nếu chúng cần tới những tài nguyên khác trên Trái đất. Có thể nó quyết định là nó cần thêm năng lượng phụ trợ, nên nó quyết định phủ kín cả hành tinh với pin mặt trời. Hoặc có thể mục tiêu ban đầu của một AI khác là viết ra càng nhiều đơn vị trong số pi càng tốt, thế là một ngày nó buộc phải biến cả Trái đất thành một cái ổ cứng lớn để chứa một lượng đơn vị khổng lồ.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Vậy là thực ra Turry chẳng “phản lại chúng ta” hay “nhảy” từ AI thân thiện sang AI không thân thiện – nó chỉ làm tiếp việc của nó trong lúc trở nên ngày càng tân tiến hơn.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Khi một hệ thống AI đạt ngưỡng AGI (thông minh như người) và rồi tiến thẳng tới ASI, đó gọi là quá trình <em>cất cánh</em> của AI. Bostrom nói rằng AGI cất cánh thành ASI có thể rất nhanh (trong đơn vị phút, giờ, hay ngày), trung bình (tháng hay năm), hoặc chậm (thập kỷ hay thế kỷ). Lời phán quyết sẽ được đưa ra khi AGI đầu tiên trên thế giới ra đời, nhưng Bostrom, người thừa nhận rằng ông không biết bao giờ chúng ta mới đạt mốc AGI, tin rằng bất kì khi nào chúng ta tới được đó, một cuộc cất cánh nhanh sẽ có khả năng cao nhất (vì những lý do được chúng ta đàm luận trong Phần 1, như là một vụ nổ trí tuệ tự tiến bộ đệ quy). Trong câu chuyện này, Turry đã có một cuộc cất cánh nhanh.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng trước khi Turry cất cánh, khi nó chưa thông minh đến thế, nó vẫn chỉ cố gắng đạt được mục tiêu cuối cùng qua những mục tiêu công cụ đơn giản như học cách quét các mẫu chữ viết nhanh hơn. Nó chẳng gây hại gì cho con người và theo định nghĩa là một AI thân thiện.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Nhưng khi một máy tính cất cánh và đạt siêu trí tuệ, Bostrom chỉ ra rằng cỗ máy không chỉ phát triển IQ cao hơn – mà nó đạt được cả một thứ mà ông gọi là <em>sức mạnh siêu nhiên</em>.</span></p> 
<p style="text-align: justify;"><span style="color: #000000;">Sức mạnh siêu nhiên là những tài năng nhận thức và được sạc năng lượng khi trí tuệ cơ bản tăng lên, bao gồm: (17)</span></p> 
<ul style="text-align: justify;"> 
 <li><span style="color: #000000;"><strong>Tự phóng đại trí thông minh.</strong> Máy tính trở nên giỏi hơn trong việc tự làm cho nó trở nên thông minh hơn, và biến đó thành một vòng lặp vô tận.</span></li> 
 <li><span style="color: #000000;"><strong>Vạch chiến lược.</strong> Máy tính có thể tạo ra, phân tích và ưu tiên các kế hoạch dài hạn một cách có chiến lược. Nó cũng có thể thông minh và đi trước một bước so với những thứ có trí tuệ ở mức thấp hơn.</span></li> 
 <li><span style="color: #000000;"><strong>Thao túng giao tiếp xã hội.</strong> Máy tính giỏi hơn trong việc thuyết phục.</span></li> 
 <li><span style="color: #000000;">Những kỹ năng khác như là<strong> lập trình và hack máy tính, nghiên cứu công nghệ, và khả năng làm việc với hệ thống tài chính để làm ra tiền.</strong></span></li> 
</ul> 
<p style="text-align: justify;"><span style="color: #000000;">Để hiểu được chúng ta sẽ không thể sánh nổi với ASI đến thế nào, hãy nhớ rằng ASI giỏi hơn loài người tới <em>hàng tỷ lần</em> trong <em>từng</em> lĩnh vực đó.</span></p> 
<p style="text-align: justify;">&nbsp;</p> 
<p><strong>Dịch</strong>:&nbsp;<a href="https://liemaximun1208.wordpress.com/2017/03/16/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung/">https://liemaximun1208.wordpress.com/2017/03/16/cuoc-cach-mang-tri-tue-nhan-tao-nhan-loai-se-tro-nen-bat-tu-hay-diet-chung/</a></p> 
<p><strong>Nguồn</strong>:&nbsp;<a href="http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html">http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html</a></p> 
<p>&nbsp;</p> 
<p>&nbsp;</p>